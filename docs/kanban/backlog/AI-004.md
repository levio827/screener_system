# AI-004: AI Screening Recommendations

## Metadata

| Field | Value |
|-------|-------|
| **ID** | AI-004 |
| **Title** | AI-powered Stock Screening Recommendations |
| **Type** | Feature |
| **Status** | BACKLOG |
| **Priority** | P1 (High) |
| **Estimate** | 16 hours |
| **Sprint** | Sprint 6 |
| **Epic** | AI/Machine Learning Features |
| **Assignee** | TBD |
| **Depends On** | AI-002b |
| **Created** | 2025-11-29 |
| **Tags** | `ai`, `recommendations`, `collaborative-filtering`, `personalization`, `explainability` |
| **Blocks** | None |

## Description

Develop a personalized stock recommendation engine that combines user screening history, behavioral patterns, and AI prediction scores using collaborative filtering and hybrid recommendation algorithms. Include explainability features to help users understand why specific stocks are recommended.

## Progress

**0% - Not started**

---

## Acceptance Criteria

- [ ] User screening history analysis and feature extraction
- [ ] Collaborative filtering-based recommendation engine (User-based + Item-based)
- [ ] Hybrid ranking algorithm combining AI prediction scores and user preferences
- [ ] "Today's Recommended Stocks" section UI with personalized cards
- [ ] Recommendation reasoning explanation (Explainability) with confidence scores
- [ ] Recommendation performance tracking and user feedback loop
- [ ] A/B testing framework for recommendation algorithms
- [ ] Daily recommendation email digest (optional)

---

## Subtasks

### 1. Data Collection & Feature Engineering
- [ ] User behavior tracking system
  - [ ] Track screening queries (filters, sort orders, time spent)
  - [ ] Track stock interactions (views, watchlist adds, purchases)
  - [ ] Track temporal patterns (preferred trading times, frequency)
- [ ] Feature extraction pipeline
  - [ ] User profile features (risk tolerance, sector preferences, price range)
  - [ ] Stock features (technical indicators, fundamentals, market cap)
  - [ ] Interaction features (implicit feedback, dwell time, click-through rate)
- [ ] Data storage optimization
  - [ ] Design user behavior event schema
  - [ ] Implement time-series aggregation for performance
  - [ ] Add data retention policies (GDPR compliance)

### 2. Recommendation Engine Implementation
- [ ] Collaborative filtering algorithms
  - [ ] User-based CF: Find similar users based on screening patterns
  - [ ] Item-based CF: Find similar stocks based on user interactions
  - [ ] Matrix factorization (ALS/SVD) for scalability
- [ ] Content-based filtering
  - [ ] Stock similarity based on technical indicators
  - [ ] Sector and industry clustering
  - [ ] Fundamental metrics similarity
- [ ] Hybrid recommendation model
  - [ ] Combine CF + content-based + AI predictions
  - [ ] Implement weighted ensemble with learned weights
  - [ ] Add diversity and novelty constraints
- [ ] Cold start handling
  - [ ] New user recommendations (popularity-based)
  - [ ] New stock recommendations (content-based)
  - [ ] Warm-up strategy with minimal user data

### 3. Explainability & Trust
- [ ] Recommendation reasoning generator
  - [ ] Template-based explanation generation
  - [ ] Feature importance extraction from model
  - [ ] Similar user/stock examples
- [ ] Confidence score calculation
  - [ ] Combine prediction confidence + recommendation score
  - [ ] Calibrate scores using historical performance
  - [ ] Display uncertainty for low-confidence recommendations
- [ ] User feedback integration
  - [ ] "Why this recommendation?" expandable section
  - [ ] Thumbs up/down feedback mechanism
  - [ ] "Not interested" filtering with reason collection

### 4. Performance Tracking & Optimization
- [ ] Recommendation metrics dashboard
  - [ ] Click-through rate (CTR) monitoring
  - [ ] Conversion rate (watchlist add, purchase)
  - [ ] Diversity and coverage metrics
  - [ ] User satisfaction scores
- [ ] A/B testing framework
  - [ ] Multi-arm bandit for algorithm selection
  - [ ] Statistical significance testing
  - [ ] Automated winner selection and rollout
- [ ] Model retraining pipeline
  - [ ] Daily incremental training on new user data
  - [ ] Weekly full retraining with hyperparameter tuning
  - [ ] Model versioning and rollback support

### 5. Frontend UI Development
- [ ] "Today's Recommendations" section
  - [ ] Personalized stock cards with key metrics
  - [ ] Inline explanation snippets
  - [ ] "Show more like this" action
- [ ] Recommendation detail view
  - [ ] Full explanation with supporting evidence
  - [ ] Related stocks carousel
  - [ ] Performance history chart
- [ ] User preference settings
  - [ ] Recommendation frequency control
  - [ ] Sector/industry exclusions
  - [ ] Risk level preferences
- [ ] Email digest implementation
  - [ ] Daily/weekly recommendation email template
  - [ ] Unsubscribe and preference management
  - [ ] Email click tracking for feedback loop

### 6. Testing & Quality Assurance
- [ ] Unit tests for recommendation algorithms
  - [ ] Test CF similarity calculations
  - [ ] Test ranking algorithm correctness
  - [ ] Test cold start handling
- [ ] Integration tests
  - [ ] Test end-to-end recommendation flow
  - [ ] Test real-time vs batch recommendations
  - [ ] Test user feedback integration
- [ ] Offline evaluation
  - [ ] Precision@K, Recall@K, NDCG metrics
  - [ ] Historical backtesting on past user data
  - [ ] Coverage and diversity analysis

---

## Implementation Details

### User Behavior Tracking

```python
# src/services/user_behavior_tracker.py
from typing import Dict, List, Optional
from datetime import datetime
from enum import Enum
from pydantic import BaseModel

class EventType(str, Enum):
    SCREEN_VIEW = "screen_view"
    STOCK_VIEW = "stock_view"
    STOCK_CLICK = "stock_click"
    WATCHLIST_ADD = "watchlist_add"
    WATCHLIST_REMOVE = "watchlist_remove"
    FILTER_APPLY = "filter_apply"
    SORT_CHANGE = "sort_change"

class UserBehaviorEvent(BaseModel):
    user_id: str
    event_type: EventType
    timestamp: datetime
    stock_code: Optional[str] = None
    metadata: Dict = {}
    session_id: str
    device_type: str

class UserBehaviorTracker:
    """Track and store user interactions for recommendation system"""

    def __init__(self, event_store: EventStore, analytics: Analytics):
        self.event_store = event_store
        self.analytics = analytics

    async def track_event(self, event: UserBehaviorEvent):
        """Track user behavior event"""
        # Store event for offline processing
        await self.event_store.append(event)

        # Update real-time analytics
        await self.analytics.update_metrics(
            user_id=event.user_id,
            event_type=event.event_type,
            timestamp=event.timestamp
        )

        # Trigger real-time recommendation updates if needed
        if event.event_type in [EventType.WATCHLIST_ADD, EventType.STOCK_CLICK]:
            await self._update_user_profile(event.user_id)

    async def get_user_screening_history(
        self,
        user_id: str,
        days: int = 30
    ) -> List[Dict]:
        """Retrieve user's screening history for feature extraction"""
        events = await self.event_store.query(
            user_id=user_id,
            event_types=[EventType.SCREEN_VIEW, EventType.FILTER_APPLY],
            since=datetime.utcnow() - timedelta(days=days)
        )

        # Aggregate into screening sessions
        sessions = self._aggregate_into_sessions(events)

        return [
            {
                "session_id": s.session_id,
                "filters": s.applied_filters,
                "viewed_stocks": s.viewed_stocks,
                "duration_seconds": s.duration,
                "timestamp": s.start_time,
            }
            for s in sessions
        ]

    async def extract_user_preferences(self, user_id: str) -> Dict:
        """Extract user preferences from behavior history"""
        history = await self.get_user_screening_history(user_id, days=90)

        # Analyze filter patterns
        filter_counts = {}
        sector_views = {}
        price_ranges = []

        for session in history:
            for filter_name, filter_value in session["filters"].items():
                filter_counts[filter_name] = filter_counts.get(filter_name, 0) + 1

            for stock in session["viewed_stocks"]:
                sector = stock.get("sector")
                if sector:
                    sector_views[sector] = sector_views.get(sector, 0) + 1

                price = stock.get("price")
                if price:
                    price_ranges.append(price)

        # Calculate preferences
        preferred_sectors = sorted(
            sector_views.items(),
            key=lambda x: x[1],
            reverse=True
        )[:3]

        avg_price_range = (
            np.percentile(price_ranges, 25),
            np.percentile(price_ranges, 75)
        ) if price_ranges else (0, 0)

        return {
            "preferred_sectors": [s[0] for s in preferred_sectors],
            "price_range": avg_price_range,
            "active_filters": [
                k for k, v in filter_counts.items()
                if v >= len(history) * 0.3  # Used in 30%+ of sessions
            ],
            "activity_level": len(history) / 90,  # Sessions per day
        }
```

### Collaborative Filtering Recommendation Engine

```python
# src/services/recommendation_engine.py
from typing import List, Dict, Tuple
import numpy as np
from scipy.sparse import csr_matrix
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import TruncatedSVD

class CollaborativeFilteringRecommender:
    """Collaborative filtering recommendation engine"""

    def __init__(self, min_interactions: int = 5):
        self.min_interactions = min_interactions
        self.user_item_matrix = None
        self.user_similarity = None
        self.item_similarity = None
        self.svd_model = None

    async def fit(self, user_interactions: List[Dict]):
        """Train collaborative filtering model on user interactions"""
        # Build user-item interaction matrix
        user_ids = sorted(set(i["user_id"] for i in user_interactions))
        stock_codes = sorted(set(i["stock_code"] for i in user_interactions))

        user_idx = {u: i for i, u in enumerate(user_ids)}
        stock_idx = {s: i for i, s in enumerate(stock_codes)}

        # Create sparse matrix (implicit feedback: view count + watch add)
        data = []
        rows = []
        cols = []

        for interaction in user_interactions:
            u_id = user_idx[interaction["user_id"]]
            s_id = stock_idx[interaction["stock_code"]]
            score = self._calculate_interaction_score(interaction)

            data.append(score)
            rows.append(u_id)
            cols.append(s_id)

        self.user_item_matrix = csr_matrix(
            (data, (rows, cols)),
            shape=(len(user_ids), len(stock_codes))
        )

        # Compute user similarity (user-based CF)
        self.user_similarity = cosine_similarity(self.user_item_matrix)

        # Compute item similarity (item-based CF)
        self.item_similarity = cosine_similarity(self.user_item_matrix.T)

        # Train matrix factorization model
        self.svd_model = TruncatedSVD(n_components=50, random_state=42)
        self.user_factors = self.svd_model.fit_transform(self.user_item_matrix)
        self.item_factors = self.svd_model.components_.T

        # Store mappings for inference
        self.user_idx = user_idx
        self.stock_idx = stock_idx
        self.idx_to_stock = {v: k for k, v in stock_idx.items()}

    def _calculate_interaction_score(self, interaction: Dict) -> float:
        """Calculate implicit feedback score from interaction"""
        score = 0.0

        # View counts
        score += interaction.get("view_count", 0) * 1.0

        # Watchlist add
        if interaction.get("in_watchlist"):
            score += 10.0

        # Dwell time (normalized)
        dwell_seconds = interaction.get("dwell_time_seconds", 0)
        score += min(dwell_seconds / 60, 5.0)  # Cap at 5 points for 5+ minutes

        return score

    async def recommend_user_based(
        self,
        user_id: str,
        top_k: int = 10,
        exclude_seen: bool = True
    ) -> List[Tuple[str, float]]:
        """Generate recommendations using user-based collaborative filtering"""
        if user_id not in self.user_idx:
            return await self._cold_start_recommend(top_k)

        user_idx = self.user_idx[user_id]

        # Find similar users
        user_sims = self.user_similarity[user_idx]
        similar_users = np.argsort(user_sims)[::-1][1:21]  # Top 20 similar users

        # Aggregate items from similar users (weighted by similarity)
        scores = np.zeros(self.user_item_matrix.shape[1])
        for sim_user_idx in similar_users:
            sim_score = user_sims[sim_user_idx]
            scores += self.user_item_matrix[sim_user_idx].toarray()[0] * sim_score

        # Exclude already seen items
        if exclude_seen:
            seen_items = self.user_item_matrix[user_idx].toarray()[0] > 0
            scores[seen_items] = -np.inf

        # Get top K recommendations
        top_indices = np.argsort(scores)[::-1][:top_k]

        return [
            (self.idx_to_stock[idx], scores[idx])
            for idx in top_indices
            if scores[idx] > 0
        ]

    async def recommend_item_based(
        self,
        user_id: str,
        top_k: int = 10
    ) -> List[Tuple[str, float]]:
        """Generate recommendations using item-based collaborative filtering"""
        if user_id not in self.user_idx:
            return await self._cold_start_recommend(top_k)

        user_idx = self.user_idx[user_id]

        # Get user's interacted items
        user_items = self.user_item_matrix[user_idx].toarray()[0]
        interacted_indices = np.where(user_items > 0)[0]

        if len(interacted_indices) == 0:
            return await self._cold_start_recommend(top_k)

        # Find similar items to user's interacted items
        scores = np.zeros(self.user_item_matrix.shape[1])
        for item_idx in interacted_indices:
            item_sims = self.item_similarity[item_idx]
            scores += item_sims * user_items[item_idx]

        # Exclude already seen items
        scores[interacted_indices] = -np.inf

        # Get top K recommendations
        top_indices = np.argsort(scores)[::-1][:top_k]

        return [
            (self.idx_to_stock[idx], scores[idx])
            for idx in top_indices
            if scores[idx] > 0
        ]

    async def recommend_matrix_factorization(
        self,
        user_id: str,
        top_k: int = 10
    ) -> List[Tuple[str, float]]:
        """Generate recommendations using matrix factorization"""
        if user_id not in self.user_idx:
            return await self._cold_start_recommend(top_k)

        user_idx = self.user_idx[user_id]

        # Compute predicted scores: user_factors @ item_factors.T
        user_vector = self.user_factors[user_idx]
        predicted_scores = user_vector @ self.item_factors.T

        # Exclude already seen items
        seen_items = self.user_item_matrix[user_idx].toarray()[0] > 0
        predicted_scores[seen_items] = -np.inf

        # Get top K recommendations
        top_indices = np.argsort(predicted_scores)[::-1][:top_k]

        return [
            (self.idx_to_stock[idx], predicted_scores[idx])
            for idx in top_indices
        ]

    async def _cold_start_recommend(self, top_k: int) -> List[Tuple[str, float]]:
        """Handle cold start with popularity-based recommendations"""
        # Calculate item popularity (total interactions)
        item_popularity = np.asarray(self.user_item_matrix.sum(axis=0)).flatten()

        top_indices = np.argsort(item_popularity)[::-1][:top_k]

        return [
            (self.idx_to_stock[idx], item_popularity[idx])
            for idx in top_indices
        ]
```

### Hybrid Recommendation System

```python
# src/services/hybrid_recommender.py
from typing import List, Dict, Tuple
from src.services.recommendation_engine import CollaborativeFilteringRecommender
from src.services.ai_prediction_service import AIPredictionService

class HybridRecommender:
    """Hybrid recommendation system combining CF, content-based, and AI predictions"""

    def __init__(
        self,
        cf_recommender: CollaborativeFilteringRecommender,
        ai_predictor: AIPredictionService,
        weights: Dict[str, float] = None
    ):
        self.cf_recommender = cf_recommender
        self.ai_predictor = ai_predictor

        # Default weights for ensemble
        self.weights = weights or {
            "user_cf": 0.3,
            "item_cf": 0.2,
            "matrix_factorization": 0.2,
            "ai_prediction": 0.3,
        }

    async def recommend(
        self,
        user_id: str,
        top_k: int = 10,
        diversity_factor: float = 0.2
    ) -> List[Dict]:
        """Generate hybrid recommendations with explanations"""
        # Get recommendations from different sources
        user_cf_recs = await self.cf_recommender.recommend_user_based(user_id, top_k * 2)
        item_cf_recs = await self.cf_recommender.recommend_item_based(user_id, top_k * 2)
        mf_recs = await self.cf_recommender.recommend_matrix_factorization(user_id, top_k * 2)

        # Get AI predictions for candidate stocks
        candidate_stocks = set()
        for recs in [user_cf_recs, item_cf_recs, mf_recs]:
            candidate_stocks.update([stock for stock, _ in recs])

        ai_predictions = await self.ai_predictor.batch_predict(list(candidate_stocks))

        # Combine scores with weights
        combined_scores = {}
        explanations = {}

        for stock in candidate_stocks:
            score = 0.0
            reasons = []

            # User-based CF score
            user_cf_score = next((s for st, s in user_cf_recs if st == stock), 0)
            if user_cf_score > 0:
                score += user_cf_score * self.weights["user_cf"]
                reasons.append("Similar users also liked this stock")

            # Item-based CF score
            item_cf_score = next((s for st, s in item_cf_recs if st == stock), 0)
            if item_cf_score > 0:
                score += item_cf_score * self.weights["item_cf"]
                reasons.append("Similar to stocks you've viewed")

            # Matrix factorization score
            mf_score = next((s for st, s in mf_recs if st == stock), 0)
            if mf_score > 0:
                score += mf_score * self.weights["matrix_factorization"]

            # AI prediction score
            ai_pred = ai_predictions.get(stock, {})
            ai_score = ai_pred.get("prediction_score", 0)
            if ai_score > 0.6:  # Only consider positive predictions
                score += ai_score * self.weights["ai_prediction"]
                reasons.append(f"AI predicts {ai_pred.get('direction', 'positive')} movement")

            combined_scores[stock] = score
            explanations[stock] = reasons

        # Rank by combined score
        ranked_stocks = sorted(
            combined_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        # Apply diversity (ensure variety in sectors)
        diverse_recs = self._apply_diversity(
            ranked_stocks,
            diversity_factor=diversity_factor,
            top_k=top_k
        )

        # Build final recommendations with full details
        final_recommendations = []
        for stock_code, score in diverse_recs[:top_k]:
            stock_info = await self._get_stock_info(stock_code)
            ai_pred = ai_predictions.get(stock_code, {})

            final_recommendations.append({
                "stock_code": stock_code,
                "company_name": stock_info["name"],
                "sector": stock_info["sector"],
                "current_price": stock_info["price"],
                "recommendation_score": score,
                "confidence": self._calculate_confidence(stock_code, ai_pred),
                "reasons": explanations[stock_code],
                "ai_prediction": {
                    "direction": ai_pred.get("direction"),
                    "probability": ai_pred.get("prediction_score"),
                },
                "key_metrics": {
                    "per": stock_info.get("per"),
                    "pbr": stock_info.get("pbr"),
                    "dividend_yield": stock_info.get("dividend_yield"),
                },
            })

        return final_recommendations

    def _apply_diversity(
        self,
        ranked_stocks: List[Tuple[str, float]],
        diversity_factor: float,
        top_k: int
    ) -> List[Tuple[str, float]]:
        """Apply diversity to ensure variety in recommendations"""
        selected = []
        sector_counts = {}

        for stock_code, score in ranked_stocks:
            stock_info = self._get_stock_info_sync(stock_code)
            sector = stock_info.get("sector", "Unknown")

            # Penalize if sector is over-represented
            sector_penalty = sector_counts.get(sector, 0) * diversity_factor
            adjusted_score = score * (1 - sector_penalty)

            selected.append((stock_code, adjusted_score))
            sector_counts[sector] = sector_counts.get(sector, 0) + 1

            if len(selected) >= top_k * 2:
                break

        # Re-sort by adjusted scores
        return sorted(selected, key=lambda x: x[1], reverse=True)

    def _calculate_confidence(self, stock_code: str, ai_pred: Dict) -> float:
        """Calculate overall confidence score for recommendation"""
        # Combine multiple signals
        cf_confidence = 0.7  # Based on collaborative filtering strength
        ai_confidence = ai_pred.get("prediction_score", 0.5)

        # Weighted average
        overall_confidence = (cf_confidence + ai_confidence) / 2

        return round(overall_confidence, 2)
```

### Explainability Component

```python
# src/services/recommendation_explainer.py
from typing import List, Dict

class RecommendationExplainer:
    """Generate human-readable explanations for recommendations"""

    EXPLANATION_TEMPLATES = {
        "similar_users": "Users with similar preferences also viewed this stock",
        "similar_stocks": "Similar to {stock_names} which you recently viewed",
        "ai_positive": "AI predicts a {confidence}% chance of price increase",
        "sector_preference": "Matches your preference for {sector} sector",
        "price_range": "Within your typical price range (${min}-${max})",
        "fundamental_strong": "Strong fundamentals: PER {per}, PBR {pbr}",
        "technical_bullish": "Bullish technical signals: {indicators}",
        "trending": "Trending among top-performing stocks this week",
    }

    async def explain(
        self,
        stock_code: str,
        recommendation_data: Dict,
        user_preferences: Dict
    ) -> Dict:
        """Generate detailed explanation for a recommendation"""
        explanations = []
        confidence_factors = []

        # Collaborative filtering explanation
        if "similar_users" in recommendation_data.get("reasons", []):
            explanations.append({
                "type": "social",
                "text": self.EXPLANATION_TEMPLATES["similar_users"],
                "confidence": 0.75,
            })
            confidence_factors.append(0.75)

        # Content-based explanation
        if stock_code in user_preferences.get("preferred_sectors", []):
            explanations.append({
                "type": "preference",
                "text": self.EXPLANATION_TEMPLATES["sector_preference"].format(
                    sector=recommendation_data["sector"]
                ),
                "confidence": 0.8,
            })
            confidence_factors.append(0.8)

        # AI prediction explanation
        ai_pred = recommendation_data.get("ai_prediction", {})
        if ai_pred.get("probability", 0) > 0.6:
            confidence_pct = int(ai_pred["probability"] * 100)
            explanations.append({
                "type": "ai",
                "text": self.EXPLANATION_TEMPLATES["ai_positive"].format(
                    confidence=confidence_pct
                ),
                "confidence": ai_pred["probability"],
            })
            confidence_factors.append(ai_pred["probability"])

        # Fundamental analysis explanation
        key_metrics = recommendation_data.get("key_metrics", {})
        if key_metrics.get("per") and key_metrics["per"] < 15:
            explanations.append({
                "type": "fundamental",
                "text": self.EXPLANATION_TEMPLATES["fundamental_strong"].format(
                    per=key_metrics["per"],
                    pbr=key_metrics.get("pbr", "N/A")
                ),
                "confidence": 0.7,
            })
            confidence_factors.append(0.7)

        # Calculate overall explanation confidence
        overall_confidence = sum(confidence_factors) / len(confidence_factors) if confidence_factors else 0.5

        return {
            "stock_code": stock_code,
            "explanations": explanations,
            "overall_confidence": round(overall_confidence, 2),
            "summary": self._generate_summary(explanations),
        }

    def _generate_summary(self, explanations: List[Dict]) -> str:
        """Generate concise summary of top reasons"""
        top_reasons = sorted(explanations, key=lambda x: x["confidence"], reverse=True)[:2]
        return " | ".join([r["text"] for r in top_reasons])
```

### REST API Endpoints

```python
# src/api/routes/recommendations.py
from fastapi import APIRouter, Depends, Query
from typing import List
from src.services.hybrid_recommender import HybridRecommender
from src.services.recommendation_explainer import RecommendationExplainer

router = APIRouter(prefix="/v1/recommendations", tags=["recommendations"])

@router.get("/daily", response_model=List[RecommendationResponse])
async def get_daily_recommendations(
    user_id: str = Depends(get_current_user_id),
    top_k: int = Query(10, ge=1, le=50),
    diversity: float = Query(0.2, ge=0.0, le=1.0),
    recommender: HybridRecommender = Depends(),
    explainer: RecommendationExplainer = Depends()
):
    """
    Get personalized daily stock recommendations

    Args:
        top_k: Number of recommendations to return
        diversity: Diversity factor (0=focused, 1=diverse)

    Returns:
        List of recommended stocks with explanations
    """
    recommendations = await recommender.recommend(
        user_id=user_id,
        top_k=top_k,
        diversity_factor=diversity
    )

    # Add detailed explanations
    user_prefs = await recommender.cf_recommender.get_user_preferences(user_id)

    for rec in recommendations:
        explanation = await explainer.explain(
            stock_code=rec["stock_code"],
            recommendation_data=rec,
            user_preferences=user_prefs
        )
        rec["explanation"] = explanation

    return recommendations

@router.post("/feedback")
async def submit_recommendation_feedback(
    feedback: RecommendationFeedback,
    user_id: str = Depends(get_current_user_id),
    tracker: FeedbackTracker = Depends()
):
    """Submit feedback on recommendation quality"""
    await tracker.record_feedback(
        user_id=user_id,
        stock_code=feedback.stock_code,
        feedback_type=feedback.feedback_type,  # "positive", "negative", "not_interested"
        reason=feedback.reason,
        timestamp=datetime.utcnow()
    )

    # Update user preferences based on feedback
    if feedback.feedback_type == "not_interested":
        await tracker.update_user_exclusions(
            user_id=user_id,
            exclude_stock=feedback.stock_code,
            reason=feedback.reason
        )

    return {"status": "success"}

@router.get("/performance")
async def get_recommendation_performance(
    user_id: str = Depends(get_current_user_id),
    days: int = Query(30, ge=1, le=365),
    analytics: RecommendationAnalytics = Depends()
):
    """Get recommendation performance metrics"""
    metrics = await analytics.calculate_metrics(
        user_id=user_id,
        days=days
    )

    return {
        "period_days": days,
        "metrics": {
            "click_through_rate": metrics["ctr"],
            "conversion_rate": metrics["conversion_rate"],
            "avg_recommendation_score": metrics["avg_score"],
            "diversity_score": metrics["diversity"],
            "user_satisfaction": metrics["satisfaction"],
        },
        "top_performing_algorithms": metrics["top_algorithms"],
    }
```

### Frontend Recommendation UI

```typescript
// src/components/recommendations/DailyRecommendations.tsx
import React, { useEffect, useState } from 'react';
import { Card, Badge, Button, Tooltip } from '@/components/ui';
import { TrendingUp, Info, ThumbsUp, ThumbsDown } from 'lucide-react';
import { useRecommendations } from '@/hooks/useRecommendations';

interface Recommendation {
  stock_code: string;
  company_name: string;
  sector: string;
  current_price: number;
  recommendation_score: number;
  confidence: number;
  reasons: string[];
  explanation: {
    explanations: Array<{ type: string; text: string; confidence: number }>;
    summary: string;
  };
  ai_prediction: {
    direction: string;
    probability: number;
  };
  key_metrics: {
    per: number;
    pbr: number;
    dividend_yield: number;
  };
}

export const DailyRecommendations: React.FC = () => {
  const { recommendations, loading, submitFeedback } = useRecommendations({
    topK: 10,
    diversity: 0.2,
  });

  const [expandedCard, setExpandedCard] = useState<string | null>(null);

  const handleFeedback = async (stockCode: string, feedbackType: 'positive' | 'negative') => {
    await submitFeedback({
      stock_code: stockCode,
      feedback_type: feedbackType,
      timestamp: new Date().toISOString(),
    });
  };

  if (loading) {
    return <div className="text-center py-8">Loading recommendations...</div>;
  }

  return (
    <div className="space-y-4">
      <div className="flex items-center justify-between mb-6">
        <h2 className="text-2xl font-bold">Today's Recommended Stocks</h2>
        <Badge variant="info">
          {recommendations.length} personalized picks
        </Badge>
      </div>

      <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
        {recommendations.map((rec) => (
          <Card
            key={rec.stock_code}
            className="p-4 hover:shadow-lg transition-shadow cursor-pointer"
            onClick={() => setExpandedCard(
              expandedCard === rec.stock_code ? null : rec.stock_code
            )}
          >
            {/* Stock Header */}
            <div className="flex items-start justify-between mb-3">
              <div>
                <h3 className="font-semibold text-lg">{rec.stock_code}</h3>
                <p className="text-sm text-gray-600">{rec.company_name}</p>
              </div>
              <Badge variant="success">
                {(rec.confidence * 100).toFixed(0)}%
              </Badge>
            </div>

            {/* Price & AI Prediction */}
            <div className="flex items-center justify-between mb-3">
              <div>
                <p className="text-2xl font-bold">${rec.current_price.toFixed(2)}</p>
                <p className="text-xs text-gray-500">{rec.sector}</p>
              </div>
              {rec.ai_prediction.probability > 0.6 && (
                <div className="flex items-center gap-1 text-green-600">
                  <TrendingUp size={20} />
                  <span className="text-sm font-medium">
                    {(rec.ai_prediction.probability * 100).toFixed(0)}%
                  </span>
                </div>
              )}
            </div>

            {/* Key Metrics */}
            <div className="grid grid-cols-3 gap-2 mb-3 text-center">
              <div>
                <p className="text-xs text-gray-500">PER</p>
                <p className="font-medium">{rec.key_metrics.per?.toFixed(1) || 'N/A'}</p>
              </div>
              <div>
                <p className="text-xs text-gray-500">PBR</p>
                <p className="font-medium">{rec.key_metrics.pbr?.toFixed(1) || 'N/A'}</p>
              </div>
              <div>
                <p className="text-xs text-gray-500">Yield</p>
                <p className="font-medium">{rec.key_metrics.dividend_yield?.toFixed(1)}%</p>
              </div>
            </div>

            {/* Explanation Summary */}
            <div className="border-t pt-3 mb-3">
              <div className="flex items-start gap-2">
                <Info size={16} className="text-blue-500 mt-0.5" />
                <p className="text-sm text-gray-700">{rec.explanation.summary}</p>
              </div>
            </div>

            {/* Expanded Details */}
            {expandedCard === rec.stock_code && (
              <div className="border-t pt-3 space-y-2">
                <p className="text-sm font-semibold">Why recommended:</p>
                {rec.explanation.explanations.map((exp, idx) => (
                  <div key={idx} className="flex items-start gap-2 text-sm">
                    <span className="text-blue-500">•</span>
                    <span className="text-gray-700">{exp.text}</span>
                    <Badge variant="outline" size="sm">
                      {(exp.confidence * 100).toFixed(0)}%
                    </Badge>
                  </div>
                ))}
              </div>
            )}

            {/* Feedback Actions */}
            <div className="flex gap-2 mt-3">
              <Button
                variant="outline"
                size="sm"
                className="flex-1"
                onClick={(e) => {
                  e.stopPropagation();
                  handleFeedback(rec.stock_code, 'positive');
                }}
              >
                <ThumbsUp size={16} className="mr-1" />
                Helpful
              </Button>
              <Button
                variant="outline"
                size="sm"
                className="flex-1"
                onClick={(e) => {
                  e.stopPropagation();
                  handleFeedback(rec.stock_code, 'negative');
                }}
              >
                <ThumbsDown size={16} className="mr-1" />
                Not interested
              </Button>
            </div>
          </Card>
        ))}
      </div>
    </div>
  );
};
```

---

## Testing Strategy

### Unit Tests

```python
# tests/services/test_collaborative_filtering.py
import pytest
import numpy as np
from src.services.recommendation_engine import CollaborativeFilteringRecommender

@pytest.fixture
def sample_interactions():
    return [
        {"user_id": "user1", "stock_code": "AAPL", "view_count": 5, "in_watchlist": True},
        {"user_id": "user1", "stock_code": "MSFT", "view_count": 3, "in_watchlist": False},
        {"user_id": "user2", "stock_code": "AAPL", "view_count": 2, "in_watchlist": True},
        {"user_id": "user2", "stock_code": "GOOGL", "view_count": 4, "in_watchlist": True},
        {"user_id": "user3", "stock_code": "MSFT", "view_count": 6, "in_watchlist": True},
    ]

@pytest.mark.asyncio
async def test_cf_recommender_training(sample_interactions):
    """Test collaborative filtering model training"""
    recommender = CollaborativeFilteringRecommender()
    await recommender.fit(sample_interactions)

    assert recommender.user_item_matrix is not None
    assert recommender.user_similarity is not None
    assert recommender.item_similarity is not None

@pytest.mark.asyncio
async def test_user_based_recommendations(sample_interactions):
    """Test user-based collaborative filtering recommendations"""
    recommender = CollaborativeFilteringRecommender()
    await recommender.fit(sample_interactions)

    recs = await recommender.recommend_user_based("user1", top_k=5)

    assert len(recs) > 0
    assert all(isinstance(stock, str) and isinstance(score, float) for stock, score in recs)
    # GOOGL should be recommended (similar user2 liked it)
    stock_codes = [s for s, _ in recs]
    assert "GOOGL" in stock_codes

@pytest.mark.asyncio
async def test_cold_start_handling(sample_interactions):
    """Test recommendations for new users"""
    recommender = CollaborativeFilteringRecommender()
    await recommender.fit(sample_interactions)

    recs = await recommender.recommend_user_based("new_user", top_k=5)

    # Should return popularity-based recommendations
    assert len(recs) > 0
    # AAPL should be top (most interactions)
    assert recs[0][0] == "AAPL"
```

### Integration Tests

```python
# tests/api/test_recommendation_endpoints.py
import pytest
from httpx import AsyncClient
from src.main import app

@pytest.mark.asyncio
async def test_get_daily_recommendations():
    """Test daily recommendations endpoint"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get(
            "/v1/recommendations/daily?top_k=10",
            headers={"Authorization": "Bearer test_token"}
        )

    assert response.status_code == 200
    data = response.json()
    assert len(data) <= 10
    assert all("stock_code" in rec for rec in data)
    assert all("explanation" in rec for rec in data)
    assert all("confidence" in rec for rec in data)

@pytest.mark.asyncio
async def test_submit_feedback():
    """Test recommendation feedback submission"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.post(
            "/v1/recommendations/feedback",
            json={
                "stock_code": "AAPL",
                "feedback_type": "positive",
                "reason": "Great recommendation",
            },
            headers={"Authorization": "Bearer test_token"}
        )

    assert response.status_code == 200
    assert response.json()["status"] == "success"

@pytest.mark.asyncio
async def test_recommendation_performance_metrics():
    """Test performance metrics endpoint"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get(
            "/v1/recommendations/performance?days=30",
            headers={"Authorization": "Bearer test_token"}
        )

    assert response.status_code == 200
    data = response.json()
    assert "metrics" in data
    assert "click_through_rate" in data["metrics"]
    assert "conversion_rate" in data["metrics"]
```

### Offline Evaluation

```python
# tests/evaluation/test_recommendation_metrics.py
import pytest
from src.evaluation.recommendation_metrics import RecommendationEvaluator

@pytest.mark.asyncio
async def test_precision_at_k():
    """Test precision@K metric calculation"""
    evaluator = RecommendationEvaluator()

    recommended = ["AAPL", "MSFT", "GOOGL", "AMZN", "TSLA"]
    relevant = ["AAPL", "GOOGL", "FB"]

    precision = evaluator.precision_at_k(recommended, relevant, k=5)

    assert precision == 2 / 5  # 2 relevant out of 5 recommended

@pytest.mark.asyncio
async def test_ndcg():
    """Test NDCG metric calculation"""
    evaluator = RecommendationEvaluator()

    recommended = ["AAPL", "MSFT", "GOOGL"]
    relevance_scores = [1.0, 0.0, 0.8]  # AAPL highly relevant, MSFT not relevant, GOOGL relevant

    ndcg = evaluator.calculate_ndcg(recommended, relevance_scores, k=3)

    assert 0 <= ndcg <= 1  # NDCG should be normalized
```

---

## Risk Assessment

| Risk | Severity | Probability | Mitigation |
|------|----------|-------------|------------|
| Cold start problem for new users | High | High | Implement popularity-based fallback, use demographic/signup data, prompt user for initial preferences |
| Recommendation filter bubble (echo chamber) | Medium | High | Add diversity constraints, periodically inject exploration recommendations, allow manual diversification |
| Data sparsity in user-item matrix | Medium | High | Use matrix factorization, combine with content-based filtering, leverage implicit feedback |
| Scalability issues with large user base | High | Medium | Implement incremental matrix factorization, use approximate nearest neighbors, cache recommendations |
| Privacy concerns with user tracking | High | Medium | Anonymize data, obtain explicit consent, implement data retention policies, GDPR compliance |
| Model staleness with changing market conditions | Medium | High | Daily incremental retraining, monitor recommendation quality metrics, A/B test new models |
| Poor recommendation quality hurting user trust | High | Medium | Extensive offline evaluation, gradual rollout with A/B testing, collect and act on user feedback |
| Computational cost of real-time recommendations | Medium | Medium | Pre-compute daily recommendations, use caching aggressively, optimize matrix operations |

---

## Performance Requirements

| Metric | Target | Measurement Method |
|--------|--------|-------------------|
| Recommendation API response time | < 300ms (p95) | APM monitoring (Datadog/New Relic) |
| Daily recommendation generation (batch) | < 5 minutes for 100K users | Airflow DAG monitoring |
| Model training time | < 30 minutes for incremental update | MLflow experiment tracking |
| Click-through rate (CTR) | > 15% | Analytics dashboard |
| Conversion rate (watchlist add) | > 5% | Analytics dashboard |
| User satisfaction score | > 4.0 / 5.0 | User feedback surveys |
| Recommendation diversity (unique sectors) | > 5 sectors in top 10 | Diversity metric calculation |
| Cache hit rate for recommendations | > 90% | Redis monitoring |

---

## Security Considerations

### Data Privacy
- User behavior data anonymized with hashed user IDs
- No PII (email, name) stored in recommendation system
- Data retention policy: 90 days for behavior events
- GDPR compliance: Right to deletion, data export

### Authentication & Authorization
```python
from fastapi import Depends, HTTPException
from src.core.auth import verify_token

async def get_current_user_id(token: str = Depends(verify_token)) -> str:
    """Extract user ID from authenticated token"""
    if not token.get("user_id"):
        raise HTTPException(status_code=401, detail="Invalid authentication")
    return token["user_id"]
```

### Input Validation
```python
from pydantic import BaseModel, Field, validator

class RecommendationFeedback(BaseModel):
    stock_code: str = Field(..., regex="^[A-Z0-9]{1,10}$")
    feedback_type: str = Field(..., regex="^(positive|negative|not_interested)$")
    reason: Optional[str] = Field(None, max_length=500)

    @validator('reason')
    def sanitize_reason(cls, v):
        if v:
            # Remove potentially malicious content
            return v.strip()[:500]
        return v
```

### API Security
- Rate limiting: 100 requests/hour per user for recommendations
- Prevent recommendation manipulation via fake feedback
- Audit logging for all feedback submissions
- SQL injection prevention via ORM (SQLAlchemy)

---

## Error Handling

### Graceful Degradation

```python
# src/services/hybrid_recommender.py
class HybridRecommender:
    async def recommend(
        self,
        user_id: str,
        top_k: int = 10,
        diversity_factor: float = 0.2
    ) -> List[Dict]:
        """Generate recommendations with fallback strategies"""
        try:
            # Try full hybrid recommendation
            return await self._hybrid_recommend(user_id, top_k, diversity_factor)

        except CFModelNotTrainedError:
            logger.warning("CF model not trained, falling back to content-based")
            # Fallback to content-based only
            return await self._content_based_recommend(user_id, top_k)

        except UserNotFoundError:
            logger.info(f"New user {user_id}, using cold start strategy")
            # Cold start: popularity + sector diversity
            return await self._cold_start_recommend(top_k)

        except AIPredictionServiceError as e:
            logger.error(f"AI prediction service error: {e}")
            # Continue without AI predictions
            return await self._cf_only_recommend(user_id, top_k)

        except Exception as e:
            logger.error(f"Unexpected error in recommendation: {e}", exc_info=True)
            # Ultimate fallback: trending stocks
            return await self._trending_stocks_fallback(top_k)

    async def _trending_stocks_fallback(self, top_k: int) -> List[Dict]:
        """Ultimate fallback: return trending stocks"""
        trending = await self.market_data.get_trending_stocks(limit=top_k)

        return [
            {
                "stock_code": stock["code"],
                "company_name": stock["name"],
                "sector": stock["sector"],
                "current_price": stock["price"],
                "recommendation_score": 0.5,  # Neutral score
                "confidence": 0.4,  # Low confidence
                "reasons": ["Trending stock (fallback recommendation)"],
                "explanation": {
                    "explanations": [],
                    "summary": "Popular stock this week",
                },
            }
            for stock in trending
        ]
```

### Frontend Error Handling

```typescript
// src/hooks/useRecommendations.ts
import { useState, useEffect } from 'react';
import { useToast } from '@/hooks/useToast';

export const useRecommendations = ({ topK = 10, diversity = 0.2 }) => {
  const [recommendations, setRecommendations] = useState<Recommendation[]>([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<Error | null>(null);
  const { showToast } = useToast();

  useEffect(() => {
    const fetchRecommendations = async () => {
      try {
        setLoading(true);
        const response = await fetch(
          `/v1/recommendations/daily?top_k=${topK}&diversity=${diversity}`,
          {
            headers: {
              'Authorization': `Bearer ${getAuthToken()}`,
            },
          }
        );

        if (!response.ok) {
          if (response.status === 404) {
            // No recommendations available, show empty state
            setRecommendations([]);
            showToast({
              title: 'No Recommendations',
              message: 'Start exploring stocks to get personalized recommendations!',
              type: 'info',
            });
            return;
          }
          throw new Error('Failed to fetch recommendations');
        }

        const data = await response.json();
        setRecommendations(data);
      } catch (err) {
        console.error('Recommendation fetch error:', err);
        setError(err as Error);

        // Show user-friendly error message
        showToast({
          title: 'Recommendations Unavailable',
          message: 'We could not load recommendations at this time. Please try again later.',
          type: 'error',
        });

        // Optionally load cached recommendations
        const cached = localStorage.getItem('cached_recommendations');
        if (cached) {
          setRecommendations(JSON.parse(cached));
        }
      } finally {
        setLoading(false);
      }
    };

    fetchRecommendations();
  }, [topK, diversity]);

  const submitFeedback = async (feedback: RecommendationFeedback) => {
    try {
      await fetch('/v1/recommendations/feedback', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${getAuthToken()}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(feedback),
      });

      showToast({
        title: 'Feedback Submitted',
        message: 'Thank you! This helps us improve your recommendations.',
        type: 'success',
      });
    } catch (err) {
      console.error('Feedback submission error:', err);
      // Don't show error to user for feedback failures
    }
  };

  return { recommendations, loading, error, submitFeedback };
};
```

---

## Notes

### Technical Decisions
- **Collaborative Filtering**: Chose hybrid approach (user-based + item-based + matrix factorization) for robustness
- **Implicit Feedback**: Using view counts and watchlist adds instead of explicit ratings (better user experience)
- **Explanation Generation**: Template-based approach for consistency and reliability
- **Real-time vs Batch**: Pre-compute daily recommendations in batch, update incrementally on user actions

### Future Enhancements
- Deep learning-based recommendations (Neural Collaborative Filtering)
- Contextual bandits for exploration-exploitation balance
- Session-based recommendations using RNNs
- Multi-armed bandit for dynamic weight optimization
- Cross-asset recommendations (stocks + ETFs + mutual funds)
- Social features (follow expert investors, shared watchlists)

### Machine Learning Pipeline
1. **Data Collection**: User events → Event store (Kafka/RabbitMQ)
2. **Feature Engineering**: Daily aggregation → Feature store (Feast/Redis)
3. **Model Training**: Weekly retraining → MLflow tracking
4. **Model Serving**: Batch predictions → Redis cache
5. **Monitoring**: Performance metrics → Grafana dashboard

### Open Questions
- [ ] How to handle market regime changes (bull vs bear markets)?
- [ ] Should we weight recent interactions more heavily than old ones?
- [ ] How to balance personalization vs serendipity (exploration)?
- [ ] Should recommendations be sector-aware during high volatility?
- [ ] How to incorporate news sentiment into recommendations?

---

## Dependencies

- **AI-002b**: Stock Prediction Model - Serving & API (for AI prediction scores)

## References

- [IMPROVEMENT_TICKETS.md](../../IMPROVEMENT_TICKETS.md) - Epic 1: AI/Machine Learning Features
- [Collaborative Filtering Techniques](https://developers.google.com/machine-learning/recommendation/collaborative/basics)
- [Recommendation System Explainability](https://arxiv.org/abs/1804.11192)
- [Implicit Feedback for Recommender Systems](https://implicit.readthedocs.io/)
