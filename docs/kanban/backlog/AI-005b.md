# AI-005b: LLM Integration - NL Query & Frontend

## Metadata

| Field | Value |
|-------|-------|
| **ID** | AI-005b |
| **Title** | LLM Integration - Natural Language Query & UI |
| **Type** | Feature |
| **Status** | BACKLOG |
| **Priority** | P2 (Medium) |
| **Estimate** | 8 hours |
| **Sprint** | Sprint 7 |
| **Epic** | AI/Machine Learning Features |
| **Assignee** | TBD |
| **Depends On** | AI-005a |
| **Created** | 2025-11-29 |
| **Tags** | `llm`, `natural-language`, `query-parser`, `ui`, `conversational-ai` |
| **Blocks** | None |

## Description

Implement natural language stock screening queries and portfolio insights UI powered by LLM. Enable users to search stocks using conversational language (e.g., "semiconductor stocks with PER under 10 and strong cash flow") and view AI-generated analysis reports with interactive visualizations.

## Progress

**0% - Not started**

---

## Acceptance Criteria

- [ ] Natural language screening query support with intent recognition
- [ ] Query to filter conversion logic with LLM-powered parsing
- [ ] Portfolio-wide AI insights generation (risk, diversity, opportunities)
- [ ] AI analysis report UI component with expandable sections
- [ ] Report sharing/download functionality (PDF, link sharing)
- [ ] Query suggestion and auto-completion
- [ ] Conversational follow-up queries ("show me more like these")

---

## Subtasks

### 1. Natural Language Query Parser
- [ ] Query intent classification
  - [ ] Screening query detection ("find stocks...")
  - [ ] Analysis query detection ("analyze AAPL...")
  - [ ] Comparison query detection ("compare AAPL vs MSFT...")
  - [ ] Portfolio query detection ("analyze my portfolio...")
- [ ] Entity extraction
  - [ ] Stock symbols/names extraction
  - [ ] Numeric values (PER, price, market cap)
  - [ ] Sectors and industries
  - [ ] Comparison operators (>, <, between)
- [ ] Filter generation
  - [ ] Convert NL query to structured filters
  - [ ] Validate filter combinations
  - [ ] Handle ambiguous queries with clarification prompts

### 2. Query-to-Filter Conversion
- [ ] LLM prompt engineering for query parsing
  - [ ] Design parsing prompt templates
  - [ ] Add few-shot examples for accuracy
  - [ ] Implement validation and error handling
- [ ] Filter schema mapping
  - [ ] Map NL terms to database fields
  - [ ] Handle synonyms and variations
  - [ ] Support complex boolean logic (AND/OR)
- [ ] Query validation
  - [ ] Check for conflicting filters
  - [ ] Suggest corrections for invalid queries
  - [ ] Limit filter complexity

### 3. Portfolio Insights Generation
- [ ] Portfolio analysis service
  - [ ] Aggregate portfolio metrics
  - [ ] Calculate diversity scores
  - [ ] Identify concentration risks
  - [ ] Find correlation patterns
- [ ] LLM-powered insights
  - [ ] Generate natural language summary
  - [ ] Identify improvement opportunities
  - [ ] Suggest rebalancing strategies
  - [ ] Highlight upcoming risks/catalysts
- [ ] Comparative benchmarking
  - [ ] Compare vs market indices
  - [ ] Compare vs sector averages
  - [ ] Trend analysis over time

### 4. Analysis Report UI
- [ ] Report display component
  - [ ] Structured layout with sections (overview, strengths, risks, etc.)
  - [ ] Expandable/collapsible sections
  - [ ] Inline charts and visualizations
  - [ ] Syntax highlighting for key metrics
- [ ] Interactive elements
  - [ ] Click to see detailed explanations
  - [ ] Related stock suggestions
  - [ ] Drill-down into specific metrics
  - [ ] Real-time data updates
- [ ] Responsive design
  - [ ] Mobile-optimized layout
  - [ ] Print-friendly formatting
  - [ ] Dark mode support

### 5. Query Interface
- [ ] Search input component
  - [ ] Natural language input field
  - [ ] Query suggestions dropdown
  - [ ] Example queries for guidance
  - [ ] Voice input support (optional)
- [ ] Auto-completion
  - [ ] Stock name/symbol suggestions
  - [ ] Metric name suggestions
  - [ ] Query template suggestions
- [ ] Query history
  - [ ] Save recent queries
  - [ ] Bookmark favorite queries
  - [ ] Share queries with others

### 6. Report Sharing & Export
- [ ] PDF generation
  - [ ] Generate professional PDF reports
  - [ ] Include charts and tables
  - [ ] Branded header/footer
- [ ] Link sharing
  - [ ] Generate shareable links
  - [ ] Access control (public/private)
  - [ ] Expiration dates for shared links
- [ ] Export formats
  - [ ] JSON data export
  - [ ] CSV for tabular data
  - [ ] Email report delivery

### 7. Testing & Quality Assurance
- [ ] Unit tests for query parser
  - [ ] Test various query formats
  - [ ] Test edge cases and ambiguity
  - [ ] Test filter generation accuracy
- [ ] Integration tests
  - [ ] Test end-to-end NL query flow
  - [ ] Test report generation
  - [ ] Test sharing functionality
- [ ] User acceptance testing
  - [ ] Test with real user queries
  - [ ] Measure query success rate
  - [ ] Collect user feedback

---

## Implementation Details

### Natural Language Query Parser

```python
# src/services/nlp/query_parser.py
from typing import Dict, List, Optional
from pydantic import BaseModel
from src.services.llm.llm_manager import LLMManager

class ParsedQuery(BaseModel):
    intent: str  # "screening", "analysis", "comparison", "portfolio"
    entities: Dict[str, List[str]]
    filters: List[Dict]
    confidence: float
    ambiguities: List[str]

class NaturalLanguageQueryParser:
    """Parse natural language queries into structured filters"""

    PARSING_PROMPT_TEMPLATE = """
You are a stock screening query parser. Convert the user's natural language query into structured filters.

**User Query:** {query}

**Available Filter Fields:**
- stock_code: Stock ticker symbol (e.g., "AAPL")
- sector: Industry sector (e.g., "Technology", "Healthcare")
- market_cap: Market capitalization in billions USD
- per: Price-to-Earnings Ratio
- pbr: Price-to-Book Ratio
- roe: Return on Equity (%)
- debt_ratio: Debt-to-Equity Ratio (%)
- dividend_yield: Dividend Yield (%)
- price: Current stock price
- volume: Trading volume
- rsi: Relative Strength Index
- ma_20: 20-day Moving Average

**Operators:** >, <, >=, <=, ==, between, in

**Examples:**
Query: "semiconductor stocks with PER under 10"
Output:
```json
{
  "intent": "screening",
  "filters": [
    {"field": "sector", "operator": "in", "value": ["Semiconductor", "Technology"]},
    {"field": "per", "operator": "<", "value": 10}
  ],
  "confidence": 0.9
}
```

Query: "large cap tech companies with good dividend"
Output:
```json
{
  "intent": "screening",
  "filters": [
    {"field": "market_cap", "operator": ">", "value": 10},
    {"field": "sector", "operator": "==", "value": "Technology"},
    {"field": "dividend_yield", "operator": ">", "value": 2}
  ],
  "confidence": 0.85,
  "ambiguities": ["'good dividend' interpreted as >2%"]
}
```

Parse the user query and return JSON in the format above.
"""

    def __init__(self, llm_manager: LLMManager, cache_manager: CacheManager):
        self.llm = llm_manager
        self.cache = cache_manager

    async def parse(self, query: str) -> ParsedQuery:
        """Parse natural language query into structured filters"""
        # Check cache
        cache_key = f"nl_query:{hashlib.md5(query.encode()).hexdigest()}"
        cached = await self.cache.get(cache_key)
        if cached:
            return ParsedQuery(**json.loads(cached))

        try:
            # Sanitize input
            query = self._sanitize_query(query)

            # Build prompt
            prompt = self.PARSING_PROMPT_TEMPLATE.format(query=query)

            # Call LLM
            messages = [
                LLMMessage(role="system", content="You are a precise query parser."),
                LLMMessage(role="user", content=prompt)
            ]

            response = await self.llm.generate(
                messages=messages,
                temperature=0.1,  # Low temperature for consistent parsing
                max_tokens=1000,
                provider_preference=["openai", "anthropic"]
            )

            # Parse response
            parsed = self._extract_json(response.content)

            # Validate filters
            validated_filters = self._validate_filters(parsed.get("filters", []))

            parsed_query = ParsedQuery(
                intent=parsed.get("intent", "screening"),
                entities=parsed.get("entities", {}),
                filters=validated_filters,
                confidence=parsed.get("confidence", 0.5),
                ambiguities=parsed.get("ambiguities", [])
            )

            # Cache result (1 hour)
            await self.cache.set(cache_key, parsed_query.json(), ttl=3600)

            return parsed_query

        except Exception as e:
            logger.error(f"Query parsing failed: {e}", exc_info=True)
            raise QueryParsingError(f"Failed to parse query: {e}") from e

    def _sanitize_query(self, query: str) -> str:
        """Sanitize user query"""
        # Remove excessive whitespace
        query = " ".join(query.split())

        # Limit length
        query = query[:500]

        # Remove potentially malicious content
        forbidden = ["DROP", "DELETE", "INSERT", "UPDATE", "<script>"]
        for term in forbidden:
            query = query.replace(term, "")

        return query.strip()

    def _extract_json(self, content: str) -> Dict:
        """Extract JSON from LLM response"""
        try:
            # Find JSON block
            json_start = content.find("{")
            json_end = content.rfind("}") + 1

            if json_start >= 0 and json_end > json_start:
                json_str = content[json_start:json_end]
                return json.loads(json_str)
            else:
                raise ValueError("No JSON found in response")

        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing failed: {e}")
            raise QueryParsingError("Invalid response format") from e

    def _validate_filters(self, filters: List[Dict]) -> List[Dict]:
        """Validate and sanitize filters"""
        valid_fields = {
            "stock_code", "sector", "market_cap", "per", "pbr",
            "roe", "debt_ratio", "dividend_yield", "price", "volume",
            "rsi", "ma_20"
        }
        valid_operators = {">", "<", ">=", "<=", "==", "between", "in"}

        validated = []
        for f in filters:
            if f.get("field") not in valid_fields:
                logger.warning(f"Invalid field: {f.get('field')}")
                continue

            if f.get("operator") not in valid_operators:
                logger.warning(f"Invalid operator: {f.get('operator')}")
                continue

            validated.append(f)

        return validated
```

### Query Execution Service

```python
# src/services/nlp/query_executor.py
from typing import List, Dict
from sqlalchemy import select, and_, or_
from src.models.stock import Stock

class QueryExecutor:
    """Execute parsed queries against database"""

    def __init__(self, db_session):
        self.db = db_session

    async def execute(self, parsed_query: ParsedQuery) -> List[Dict]:
        """Execute parsed query and return results"""
        try:
            # Build SQL query from filters
            query = select(Stock)

            for filter_def in parsed_query.filters:
                field = filter_def["field"]
                operator = filter_def["operator"]
                value = filter_def["value"]

                # Build condition
                column = getattr(Stock, field, None)
                if column is None:
                    logger.warning(f"Unknown column: {field}")
                    continue

                if operator == ">":
                    query = query.where(column > value)
                elif operator == "<":
                    query = query.where(column < value)
                elif operator == ">=":
                    query = query.where(column >= value)
                elif operator == "<=":
                    query = query.where(column <= value)
                elif operator == "==":
                    query = query.where(column == value)
                elif operator == "between" and isinstance(value, list) and len(value) == 2:
                    query = query.where(column.between(value[0], value[1]))
                elif operator == "in" and isinstance(value, list):
                    query = query.where(column.in_(value))

            # Execute query
            result = await self.db.execute(query)
            stocks = result.scalars().all()

            return [
                {
                    "stock_code": s.stock_code,
                    "company_name": s.company_name,
                    "sector": s.sector,
                    "price": s.price,
                    "per": s.per,
                    "pbr": s.pbr,
                    "market_cap": s.market_cap,
                }
                for s in stocks
            ]

        except Exception as e:
            logger.error(f"Query execution failed: {e}", exc_info=True)
            raise QueryExecutionError(f"Failed to execute query: {e}") from e
```

### Portfolio Insights Service

```python
# src/services/portfolio_insights.py
from typing import Dict, List
import numpy as np

class PortfolioInsightsService:
    """Generate AI-powered portfolio insights"""

    def __init__(
        self,
        llm_manager: LLMManager,
        portfolio_service: PortfolioService
    ):
        self.llm = llm_manager
        self.portfolio = portfolio_service

    async def generate_insights(self, user_id: str) -> Dict:
        """Generate comprehensive portfolio insights"""
        # Get portfolio data
        holdings = await self.portfolio.get_holdings(user_id)

        # Calculate metrics
        metrics = await self._calculate_metrics(holdings)

        # Build context for LLM
        context = self._build_context(holdings, metrics)

        # Generate insights with LLM
        prompt = f"""
Analyze this stock portfolio and provide actionable insights:

**Portfolio Summary:**
- Total Value: ${metrics['total_value']:,.2f}
- Number of Holdings: {len(holdings)}
- Sectors: {', '.join(metrics['sector_distribution'].keys())}

**Diversification:**
{context['diversification']}

**Performance:**
{context['performance']}

**Risk Metrics:**
{context['risk']}

Provide:
1. **Overall Assessment** (1-2 sentences)
2. **Key Strengths** (2-3 bullet points)
3. **Potential Risks** (2-3 bullet points)
4. **Recommendations** (3-5 specific actions)
5. **Opportunities** (stocks or sectors to consider)

Format as JSON:
```json
{{
  "overall_assessment": "...",
  "strengths": ["...", "..."],
  "risks": ["...", "..."],
  "recommendations": ["...", "...", "..."],
  "opportunities": ["...", "..."]
}}
```
"""

        messages = [
            LLMMessage(role="system", content="You are a portfolio analyst."),
            LLMMessage(role="user", content=prompt)
        ]

        response = await self.llm.generate(
            messages=messages,
            temperature=0.4,
            max_tokens=1500
        )

        insights = self._parse_insights(response.content)
        insights["metrics"] = metrics

        return insights

    async def _calculate_metrics(self, holdings: List[Dict]) -> Dict:
        """Calculate portfolio metrics"""
        total_value = sum(h["value"] for h in holdings)

        # Sector distribution
        sector_dist = {}
        for h in holdings:
            sector = h.get("sector", "Unknown")
            sector_dist[sector] = sector_dist.get(sector, 0) + h["value"]

        sector_pct = {
            s: (v / total_value) * 100
            for s, v in sector_dist.items()
        }

        # Diversification score (Herfindahl index)
        weights = [h["value"] / total_value for h in holdings]
        herfindahl = sum(w**2 for w in weights)
        diversification_score = (1 - herfindahl) * 100

        # Performance
        total_return = sum(h.get("unrealized_gain", 0) for h in holdings)
        total_return_pct = (total_return / total_value) * 100 if total_value > 0 else 0

        return {
            "total_value": total_value,
            "sector_distribution": sector_pct,
            "diversification_score": diversification_score,
            "total_return": total_return,
            "total_return_pct": total_return_pct,
        }

    def _build_context(self, holdings: List[Dict], metrics: Dict) -> Dict:
        """Build context for LLM prompt"""
        # Diversification context
        div_text = f"Diversification Score: {metrics['diversification_score']:.1f}/100\n"
        div_text += "Sector Allocation:\n"
        for sector, pct in sorted(
            metrics['sector_distribution'].items(),
            key=lambda x: x[1],
            reverse=True
        ):
            div_text += f"  - {sector}: {pct:.1f}%\n"

        # Performance context
        perf_text = f"Total Return: ${metrics['total_return']:,.2f} ({metrics['total_return_pct']:.2f}%)\n"
        perf_text += "Top Performers:\n"
        top_performers = sorted(
            holdings,
            key=lambda x: x.get("unrealized_gain", 0),
            reverse=True
        )[:3]
        for h in top_performers:
            gain = h.get("unrealized_gain", 0)
            perf_text += f"  - {h['stock_code']}: ${gain:,.2f}\n"

        # Risk context
        risk_text = "Concentration Risk:\n"
        concentrated = [
            (h['stock_code'], (h['value'] / metrics['total_value']) * 100)
            for h in holdings
            if (h['value'] / metrics['total_value']) > 0.15
        ]
        if concentrated:
            for code, pct in concentrated:
                risk_text += f"  - {code}: {pct:.1f}% (High concentration)\n"
        else:
            risk_text += "  - No significant concentration risks\n"

        return {
            "diversification": div_text,
            "performance": perf_text,
            "risk": risk_text,
        }

    def _parse_insights(self, content: str) -> Dict:
        """Parse LLM insights response"""
        try:
            json_start = content.find("{")
            json_end = content.rfind("}") + 1

            if json_start >= 0 and json_end > json_start:
                return json.loads(content[json_start:json_end])
            else:
                return self._fallback_parse(content)

        except json.JSONDecodeError:
            return self._fallback_parse(content)

    def _fallback_parse(self, content: str) -> Dict:
        """Fallback text parser"""
        return {
            "overall_assessment": content[:200],
            "strengths": [],
            "risks": [],
            "recommendations": [],
            "opportunities": [],
            "full_text": content,
        }
```

### REST API Endpoints

```python
# src/api/routes/nlp_query.py
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from src.services.nlp.query_parser import NaturalLanguageQueryParser
from src.services.nlp.query_executor import QueryExecutor

router = APIRouter(prefix="/v1/nlp", tags=["nlp-query"])

class NLQueryRequest(BaseModel):
    query: str

@router.post("/query")
async def natural_language_query(
    request: NLQueryRequest,
    parser: NaturalLanguageQueryParser = Depends(),
    executor: QueryExecutor = Depends()
):
    """
    Execute natural language stock screening query

    Args:
        query: Natural language query (e.g., "tech stocks with PER under 15")

    Returns:
        Parsed filters and matching stocks
    """
    try:
        # Parse query
        parsed = await parser.parse(request.query)

        # Execute query
        results = await executor.execute(parsed)

        return {
            "parsed_query": parsed.dict(),
            "result_count": len(results),
            "results": results,
        }

    except QueryParsingError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except QueryExecutionError as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/suggestions")
async def get_query_suggestions(
    partial: str = "",
    service: QuerySuggestionService = Depends()
):
    """Get query auto-completion suggestions"""
    suggestions = await service.get_suggestions(partial)

    return {
        "suggestions": suggestions,
    }

@router.get("/portfolio/insights")
async def get_portfolio_insights(
    user_id: str = Depends(get_current_user_id),
    service: PortfolioInsightsService = Depends()
):
    """Get AI-powered portfolio insights"""
    insights = await service.generate_insights(user_id)

    return insights
```

### Frontend Analysis Report Component

```typescript
// src/components/analysis/AIAnalysisReport.tsx
import React, { useState } from 'react';
import { Card, Badge, Button, Accordion } from '@/components/ui';
import { Download, Share2, ChevronDown, ChevronUp } from 'lucide-react';
import ReactMarkdown from 'react-markdown';

interface AnalysisReport {
  stock_code: string;
  overall_rating: string;
  confidence: number;
  strengths: string[];
  risks: string[];
  technical_summary: string;
  fundamental_assessment: string;
  recommendation: string;
  price_targets?: {
    conservative: number;
    moderate: number;
    optimistic: number;
  };
  metadata: {
    generated_at: string;
    model: string;
    provider: string;
  };
}

interface AIAnalysisReportProps {
  stockCode: string;
}

export const AIAnalysisReport: React.FC<AIAnalysisReportProps> = ({ stockCode }) => {
  const [report, setReport] = useState<AnalysisReport | null>(null);
  const [loading, setLoading] = useState(false);
  const [expandedSections, setExpandedSections] = useState<Set<string>>(
    new Set(['overview'])
  );

  const fetchReport = async () => {
    setLoading(true);
    try {
      const response = await fetch(`/v1/ai/analysis/${stockCode}`);
      const data = await response.json();
      setReport(data);
    } catch (error) {
      console.error('Failed to fetch analysis:', error);
    } finally {
      setLoading(false);
    }
  };

  const toggleSection = (section: string) => {
    setExpandedSections(prev => {
      const next = new Set(prev);
      if (next.has(section)) {
        next.delete(section);
      } else {
        next.add(section);
      }
      return next;
    });
  };

  const handleDownloadPDF = async () => {
    const response = await fetch(`/v1/ai/analysis/${stockCode}/pdf`);
    const blob = await response.blob();
    const url = window.URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `${stockCode}_analysis.pdf`;
    a.click();
  };

  const handleShare = async () => {
    const shareLink = `${window.location.origin}/share/analysis/${stockCode}`;
    await navigator.clipboard.writeText(shareLink);
    alert('Share link copied to clipboard!');
  };

  React.useEffect(() => {
    fetchReport();
  }, [stockCode]);

  if (loading) {
    return (
      <Card className="p-6">
        <div className="animate-pulse space-y-4">
          <div className="h-8 bg-gray-200 rounded w-1/3"></div>
          <div className="h-4 bg-gray-200 rounded w-2/3"></div>
          <div className="h-4 bg-gray-200 rounded w-1/2"></div>
        </div>
      </Card>
    );
  }

  if (!report) {
    return (
      <Card className="p-6">
        <p className="text-gray-500">No analysis available for {stockCode}</p>
      </Card>
    );
  }

  const ratingColor =
    report.overall_rating === 'Strong Buy' || report.overall_rating === 'Buy'
      ? 'green'
      : report.overall_rating === 'Hold'
      ? 'yellow'
      : 'red';

  return (
    <div className="space-y-4">
      {/* Header */}
      <Card className="p-6">
        <div className="flex items-start justify-between mb-4">
          <div>
            <h2 className="text-2xl font-bold mb-2">AI Analysis Report</h2>
            <p className="text-gray-600">{stockCode}</p>
          </div>
          <div className="flex gap-2">
            <Button variant="outline" size="sm" onClick={handleDownloadPDF}>
              <Download size={16} className="mr-1" />
              PDF
            </Button>
            <Button variant="outline" size="sm" onClick={handleShare}>
              <Share2 size={16} className="mr-1" />
              Share
            </Button>
          </div>
        </div>

        {/* Overall Rating */}
        <div className="flex items-center gap-4 mb-4">
          <Badge variant={ratingColor} size="lg">
            {report.overall_rating}
          </Badge>
          <div>
            <p className="text-sm text-gray-600">Confidence</p>
            <p className="text-2xl font-bold">{report.confidence}%</p>
          </div>
        </div>

        {/* Price Targets */}
        {report.price_targets && (
          <div className="grid grid-cols-3 gap-4 mt-4 pt-4 border-t">
            <div>
              <p className="text-xs text-gray-500">Conservative</p>
              <p className="text-lg font-semibold">
                ${report.price_targets.conservative.toFixed(2)}
              </p>
            </div>
            <div>
              <p className="text-xs text-gray-500">Moderate</p>
              <p className="text-lg font-semibold">
                ${report.price_targets.moderate.toFixed(2)}
              </p>
            </div>
            <div>
              <p className="text-xs text-gray-500">Optimistic</p>
              <p className="text-lg font-semibold">
                ${report.price_targets.optimistic.toFixed(2)}
              </p>
            </div>
          </div>
        )}
      </Card>

      {/* Strengths */}
      <Card>
        <div
          className="p-4 flex items-center justify-between cursor-pointer hover:bg-gray-50"
          onClick={() => toggleSection('strengths')}
        >
          <h3 className="font-semibold text-lg">Key Strengths</h3>
          {expandedSections.has('strengths') ? (
            <ChevronUp size={20} />
          ) : (
            <ChevronDown size={20} />
          )}
        </div>
        {expandedSections.has('strengths') && (
          <div className="p-4 pt-0 space-y-2">
            {report.strengths.map((strength, idx) => (
              <div key={idx} className="flex items-start gap-2">
                <span className="text-green-500 mt-1">✓</span>
                <p className="text-gray-700">{strength}</p>
              </div>
            ))}
          </div>
        )}
      </Card>

      {/* Risks */}
      <Card>
        <div
          className="p-4 flex items-center justify-between cursor-pointer hover:bg-gray-50"
          onClick={() => toggleSection('risks')}
        >
          <h3 className="font-semibold text-lg">Key Risks</h3>
          {expandedSections.has('risks') ? (
            <ChevronUp size={20} />
          ) : (
            <ChevronDown size={20} />
          )}
        </div>
        {expandedSections.has('risks') && (
          <div className="p-4 pt-0 space-y-2">
            {report.risks.map((risk, idx) => (
              <div key={idx} className="flex items-start gap-2">
                <span className="text-red-500 mt-1">⚠</span>
                <p className="text-gray-700">{risk}</p>
              </div>
            ))}
          </div>
        )}
      </Card>

      {/* Technical Analysis */}
      <Card>
        <div
          className="p-4 flex items-center justify-between cursor-pointer hover:bg-gray-50"
          onClick={() => toggleSection('technical')}
        >
          <h3 className="font-semibold text-lg">Technical Analysis</h3>
          {expandedSections.has('technical') ? (
            <ChevronUp size={20} />
          ) : (
            <ChevronDown size={20} />
          )}
        </div>
        {expandedSections.has('technical') && (
          <div className="p-4 pt-0">
            <ReactMarkdown className="prose max-w-none">
              {report.technical_summary}
            </ReactMarkdown>
          </div>
        )}
      </Card>

      {/* Fundamental Assessment */}
      <Card>
        <div
          className="p-4 flex items-center justify-between cursor-pointer hover:bg-gray-50"
          onClick={() => toggleSection('fundamental')}
        >
          <h3 className="font-semibold text-lg">Fundamental Assessment</h3>
          {expandedSections.has('fundamental') ? (
            <ChevronUp size={20} />
          ) : (
            <ChevronDown size={20} />
          )}
        </div>
        {expandedSections.has('fundamental') && (
          <div className="p-4 pt-0">
            <ReactMarkdown className="prose max-w-none">
              {report.fundamental_assessment}
            </ReactMarkdown>
          </div>
        )}
      </Card>

      {/* Recommendation */}
      <Card className="p-6 bg-blue-50 border-blue-200">
        <h3 className="font-semibold text-lg mb-3">Recommendation</h3>
        <p className="text-gray-800">{report.recommendation}</p>
      </Card>

      {/* Metadata */}
      <div className="text-xs text-gray-500 text-center">
        Generated on {new Date(report.metadata.generated_at).toLocaleString()}
        <br />
        Powered by {report.metadata.provider} ({report.metadata.model})
      </div>
    </div>
  );
};
```

### Natural Language Query Interface

```typescript
// src/components/search/NLQueryInput.tsx
import React, { useState, useCallback } from 'react';
import { Search, Loader } from 'lucide-react';
import { Input, Button } from '@/components/ui';
import { debounce } from 'lodash';

interface NLQueryInputProps {
  onSearch: (query: string) => void;
}

export const NLQueryInput: React.FC<NLQueryInputProps> = ({ onSearch }) => {
  const [query, setQuery] = useState('');
  const [suggestions, setSuggestions] = useState<string[]>([]);
  const [loading, setLoading] = useState(false);

  const fetchSuggestions = useCallback(
    debounce(async (partial: string) => {
      if (partial.length < 3) {
        setSuggestions([]);
        return;
      }

      try {
        const response = await fetch(`/v1/nlp/suggestions?partial=${encodeURIComponent(partial)}`);
        const data = await response.json();
        setSuggestions(data.suggestions);
      } catch (error) {
        console.error('Failed to fetch suggestions:', error);
      }
    }, 300),
    []
  );

  const handleInputChange = (value: string) => {
    setQuery(value);
    fetchSuggestions(value);
  };

  const handleSearch = async () => {
    if (!query.trim()) return;

    setLoading(true);
    try {
      await onSearch(query);
      setSuggestions([]);
    } finally {
      setLoading(false);
    }
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter') {
      handleSearch();
    }
  };

  const exampleQueries = [
    "tech stocks with PER under 15 and high ROE",
    "dividend stocks in healthcare sector",
    "undervalued large cap companies",
    "semiconductor stocks with strong cash flow"
  ];

  return (
    <div className="space-y-4">
      <div className="relative">
        <Input
          value={query}
          onChange={(e) => handleInputChange(e.target.value)}
          onKeyPress={handleKeyPress}
          placeholder="Search stocks using natural language..."
          className="pr-24 text-lg py-6"
        />
        <Button
          onClick={handleSearch}
          className="absolute right-2 top-1/2 -translate-y-1/2"
          disabled={loading || !query.trim()}
        >
          {loading ? (
            <Loader size={20} className="animate-spin" />
          ) : (
            <>
              <Search size={20} className="mr-2" />
              Search
            </>
          )}
        </Button>

        {/* Suggestions Dropdown */}
        {suggestions.length > 0 && (
          <div className="absolute top-full mt-2 w-full bg-white border rounded-lg shadow-lg z-10">
            {suggestions.map((suggestion, idx) => (
              <div
                key={idx}
                className="p-3 hover:bg-gray-100 cursor-pointer border-b last:border-b-0"
                onClick={() => {
                  setQuery(suggestion);
                  setSuggestions([]);
                }}
              >
                {suggestion}
              </div>
            ))}
          </div>
        )}
      </div>

      {/* Example Queries */}
      <div>
        <p className="text-sm text-gray-600 mb-2">Example queries:</p>
        <div className="flex flex-wrap gap-2">
          {exampleQueries.map((example, idx) => (
            <button
              key={idx}
              className="px-3 py-1 text-sm bg-gray-100 hover:bg-gray-200 rounded-full"
              onClick={() => setQuery(example)}
            >
              {example}
            </button>
          ))}
        </div>
      </div>
    </div>
  );
};
```

---

## Testing Strategy

### Unit Tests

```python
# tests/services/nlp/test_query_parser.py
import pytest
from src.services.nlp.query_parser import NaturalLanguageQueryParser

@pytest.mark.asyncio
async def test_parse_simple_query(mock_llm):
    """Test parsing simple screening query"""
    parser = NaturalLanguageQueryParser(mock_llm, mock_cache)

    query = "tech stocks with PER under 15"
    result = await parser.parse(query)

    assert result.intent == "screening"
    assert any(f["field"] == "sector" for f in result.filters)
    assert any(f["field"] == "per" and f["operator"] == "<" for f in result.filters)

@pytest.mark.asyncio
async def test_parse_complex_query(mock_llm):
    """Test parsing complex multi-filter query"""
    parser = NaturalLanguageQueryParser(mock_llm, mock_cache)

    query = "large cap semiconductor companies with PER between 10 and 20 and dividend yield over 2%"
    result = await parser.parse(query)

    assert len(result.filters) >= 3
    assert result.confidence > 0.7
```

### Integration Tests

```python
# tests/api/test_nlp_endpoints.py
@pytest.mark.asyncio
async def test_nlp_query_endpoint():
    """Test NL query endpoint"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.post(
            "/v1/nlp/query",
            json={"query": "tech stocks with low PER"}
        )

    assert response.status_code == 200
    data = response.json()
    assert "parsed_query" in data
    assert "results" in data
    assert len(data["results"]) > 0
```

---

## Risk Assessment

| Risk | Severity | Probability | Mitigation |
|------|----------|-------------|------------|
| Poor query parsing accuracy | High | Medium | Use few-shot prompting, validate with test cases, collect user feedback for improvements |
| Ambiguous queries leading to incorrect results | Medium | High | Detect ambiguities, ask clarification questions, show confidence scores |
| Slow response times for complex queries | Medium | Medium | Cache parsed queries, optimize database queries, use query timeouts |
| Security risks from query injection | High | Low | Strict input sanitization, parameterized queries, rate limiting |
| User confusion with NL interface | Medium | Medium | Provide example queries, show parsed filters, allow manual filter editing |

---

## Performance Requirements

| Metric | Target | Measurement Method |
|--------|--------|-------------------|
| Query parsing time | < 2s (p95) | API latency monitoring |
| Query execution time | < 1s (p95) | Database query profiling |
| UI responsiveness | < 100ms for interactions | Browser performance metrics |
| PDF generation time | < 3s | Server-side timing |

---

## Security Considerations

- Input validation and sanitization for all user queries
- SQL injection prevention via ORM and parameterized queries
- Rate limiting on query endpoints (10 queries/min per user)
- Content Security Policy for shared report links
- Access control for private portfolio insights

---

## Error Handling

```python
class QueryParsingError(Exception):
    """Query parsing failed"""
    pass

class QueryExecutionError(Exception):
    """Query execution failed"""
    pass

# Graceful degradation
async def parse_query_with_fallback(parser, query):
    """Parse with fallback to simple keyword search"""
    try:
        return await parser.parse(query)
    except QueryParsingError:
        logger.warning("Query parsing failed, using keyword fallback")
        return simple_keyword_parse(query)
```

---

## Notes

### Technical Decisions
- **LLM for Query Parsing**: More flexible than rule-based parsing, handles natural variations
- **Caching Parsed Queries**: Saves LLM costs, improves response time
- **Expandable Report Sections**: Better UX for long reports, mobile-friendly

### Future Enhancements
- Voice input support (speech-to-text)
- Multi-turn conversational queries ("show me more like these")
- Query refinement based on results
- Saved query templates
- Collaborative query sharing

### Open Questions
- [ ] Should we support multi-language queries (Korean, Japanese)?
- [ ] How to handle very complex queries with 10+ filters?
- [ ] Should we allow users to edit parsed filters before executing?

---

## Dependencies

- **AI-005a**: LLM Integration - Backend Service (MUST be completed first)

## References

- [IMPROVEMENT_TICKETS.md](../../IMPROVEMENT_TICKETS.md) - Epic 1: AI/Machine Learning Features
- [Natural Language to SQL](https://github.com/salesforce/WikiSQL)
- [Semantic Search Best Practices](https://www.pinecone.io/learn/semantic-search/)
