# BT-002: Performance Metrics Calculator

## Metadata

| Field | Value |
|-------|-------|
| **ID** | BT-002 |
| **Title** | Implement Comprehensive Performance Metrics |
| **Type** | Feature |
| **Status** | BACKLOG |
| **Priority** | P0 (Critical) |
| **Estimate** | 12 hours |
| **Sprint** | Sprint 5 |
| **Epic** | Backtesting Engine |
| **Assignee** | TBD |
| **Depends On** | BT-001a, BT-001b |
| **Created** | 2025-11-29 |
| **Tags** | #backend #metrics #analytics #statistics |
| **Blocks** | BT-003, BT-004b |

## Description

Implement a comprehensive performance metrics calculation module that analyzes backtest results and generates detailed portfolio performance statistics. This includes return metrics (total return, CAGR), risk metrics (volatility, MDD, VaR), risk-adjusted returns (Sharpe, Sortino, Calmar ratios), trade statistics, and benchmark comparison metrics (Alpha, Beta, Information Ratio). The module will also perform statistical significance testing to validate strategy performance.

## Subtasks

### Return Metrics Implementation
- [ ] Total return calculation
  - [ ] Simple return calculation
  - [ ] Cumulative return over period
  - [ ] Annualization logic
- [ ] CAGR (Compound Annual Growth Rate)
  - [ ] Geometric mean return
  - [ ] Annualization based on actual days
  - [ ] Handle partial years correctly
- [ ] Periodic returns
  - [ ] Monthly return calculation
  - [ ] Yearly return calculation
  - [ ] Rolling period returns
- [ ] Return distribution analysis
  - [ ] Best/worst month performance
  - [ ] Positive/negative month ratio
  - [ ] Return percentiles

### Risk Metrics Implementation
- [ ] Volatility calculation
  - [ ] Daily returns standard deviation
  - [ ] Annualized volatility
  - [ ] Downside deviation
- [ ] Maximum Drawdown (MDD)
  - [ ] Running maximum tracking
  - [ ] Peak-to-trough calculation
  - [ ] Drawdown duration
  - [ ] Recovery time calculation
- [ ] Value at Risk (VaR)
  - [ ] Historical VaR at 95% confidence
  - [ ] Historical VaR at 99% confidence
  - [ ] Conditional VaR (CVaR/Expected Shortfall)
- [ ] Additional risk metrics
  - [ ] Ulcer Index
  - [ ] Downside risk
  - [ ] Semi-deviation

### Risk-Adjusted Return Metrics
- [ ] Sharpe Ratio
  - [ ] Excess return calculation
  - [ ] Risk-free rate integration
  - [ ] Annualized Sharpe ratio
- [ ] Sortino Ratio
  - [ ] Downside deviation calculation
  - [ ] Target return threshold
  - [ ] Annualized Sortino ratio
- [ ] Calmar Ratio
  - [ ] CAGR / Max Drawdown
  - [ ] Rolling Calmar ratio
- [ ] Additional ratios
  - [ ] Information Ratio
  - [ ] Treynor Ratio
  - [ ] Omega Ratio

### Trade Statistics
- [ ] Win rate calculation
  - [ ] Winning trades count
  - [ ] Losing trades count
  - [ ] Win percentage
- [ ] Profit/Loss ratio
  - [ ] Average winning trade
  - [ ] Average losing trade
  - [ ] Expectancy calculation
- [ ] Holding period analysis
  - [ ] Average holding period
  - [ ] Median holding period
  - [ ] Holding period distribution
- [ ] Trade frequency metrics
  - [ ] Trades per year
  - [ ] Average trades per rebalancing
  - [ ] Turnover rate

### Benchmark Comparison
- [ ] Alpha calculation
  - [ ] Excess return vs benchmark
  - [ ] Jensen's Alpha
  - [ ] Annualized alpha
- [ ] Beta calculation
  - [ ] Covariance with benchmark
  - [ ] Market sensitivity
  - [ ] Rolling beta
- [ ] Information Ratio
  - [ ] Tracking error calculation
  - [ ] Active return / tracking error
- [ ] Correlation analysis
  - [ ] Correlation with benchmark
  - [ ] Correlation stability
- [ ] Relative performance
  - [ ] Outperformance periods
  - [ ] Up/down capture ratios

### Statistical Testing
- [ ] T-test for returns
  - [ ] Mean return significance
  - [ ] Comparison to zero/benchmark
  - [ ] P-value calculation
- [ ] Normality tests
  - [ ] Shapiro-Wilk test
  - [ ] Jarque-Bera test
  - [ ] Q-Q plot data
- [ ] Autocorrelation testing
  - [ ] Durbin-Watson statistic
  - [ ] Ljung-Box test

### Testing
- [ ] Unit tests for each metric
  - [ ] Test with known data
  - [ ] Verify calculation accuracy
  - [ ] Edge case handling
- [ ] Integration tests
  - [ ] Full metrics calculation pipeline
  - [ ] Benchmark comparison tests
- [ ] Performance tests
  - [ ] Large dataset handling
  - [ ] Calculation speed benchmarks

## Implementation Details

### Metrics Calculator Class

```python
# backend/app/services/backtesting/metrics_calculator.py
import numpy as np
import pandas as pd
from typing import Dict, List, Optional
from decimal import Decimal
from datetime import date
from scipy import stats
from dataclasses import dataclass

@dataclass
class BacktestMetrics:
    """Complete backtest performance metrics"""
    # Return metrics
    total_return: float
    cagr: float
    monthly_returns: List[float]
    yearly_returns: List[float]
    best_month: float
    worst_month: float
    positive_months_pct: float

    # Risk metrics
    volatility: float
    downside_deviation: float
    max_drawdown: float
    max_drawdown_duration: int  # days
    var_95: float
    var_99: float
    cvar_95: float

    # Risk-adjusted metrics
    sharpe_ratio: float
    sortino_ratio: float
    calmar_ratio: float
    information_ratio: float

    # Trade metrics
    total_trades: int
    win_rate: float
    profit_loss_ratio: float
    avg_holding_period: float
    trades_per_year: float
    turnover_rate: float
    avg_win: float
    avg_loss: float
    expectancy: float

    # Benchmark comparison
    alpha: float
    beta: float
    correlation: float
    tracking_error: float
    benchmark_return: float
    outperformance: float
    up_capture: float
    down_capture: float

    # Statistical tests
    return_ttest_pvalue: float
    returns_normality_pvalue: float

class MetricsCalculator:
    """Calculate comprehensive backtesting performance metrics"""

    def __init__(self, risk_free_rate: float = 0.03):
        """
        Args:
            risk_free_rate: Annual risk-free rate (default 3%)
        """
        self.risk_free_rate = risk_free_rate

    def calculate_all_metrics(
        self,
        portfolio_values: pd.Series,  # Indexed by date
        trades: List[Dict],
        benchmark_values: Optional[pd.Series] = None
    ) -> BacktestMetrics:
        """
        Calculate all performance metrics

        Args:
            portfolio_values: Daily portfolio values indexed by date
            trades: List of trade dictionaries
            benchmark_values: Daily benchmark values (optional)

        Returns:
            BacktestMetrics with all calculated metrics
        """
        # Calculate returns
        returns = portfolio_values.pct_change().dropna()

        return BacktestMetrics(
            # Return metrics
            total_return=self._total_return(portfolio_values),
            cagr=self._cagr(portfolio_values),
            monthly_returns=self._monthly_returns(returns),
            yearly_returns=self._yearly_returns(returns),
            best_month=self._best_month(returns),
            worst_month=self._worst_month(returns),
            positive_months_pct=self._positive_months_pct(returns),

            # Risk metrics
            volatility=self._volatility(returns),
            downside_deviation=self._downside_deviation(returns),
            max_drawdown=self._max_drawdown(portfolio_values),
            max_drawdown_duration=self._max_drawdown_duration(portfolio_values),
            var_95=self._value_at_risk(returns, 0.95),
            var_99=self._value_at_risk(returns, 0.99),
            cvar_95=self._conditional_var(returns, 0.95),

            # Risk-adjusted metrics
            sharpe_ratio=self._sharpe_ratio(returns),
            sortino_ratio=self._sortino_ratio(returns),
            calmar_ratio=self._calmar_ratio(portfolio_values),
            information_ratio=self._information_ratio(
                returns, benchmark_values
            ) if benchmark_values is not None else 0.0,

            # Trade metrics
            total_trades=len(trades),
            win_rate=self._win_rate(trades),
            profit_loss_ratio=self._profit_loss_ratio(trades),
            avg_holding_period=self._avg_holding_period(trades),
            trades_per_year=self._trades_per_year(trades, portfolio_values),
            turnover_rate=self._turnover_rate(trades, portfolio_values),
            avg_win=self._avg_win(trades),
            avg_loss=self._avg_loss(trades),
            expectancy=self._expectancy(trades),

            # Benchmark comparison
            alpha=self._alpha(returns, benchmark_values) if benchmark_values is not None else 0.0,
            beta=self._beta(returns, benchmark_values) if benchmark_values is not None else 1.0,
            correlation=self._correlation(returns, benchmark_values) if benchmark_values is not None else 0.0,
            tracking_error=self._tracking_error(returns, benchmark_values) if benchmark_values is not None else 0.0,
            benchmark_return=self._total_return(benchmark_values) if benchmark_values is not None else 0.0,
            outperformance=self._outperformance(portfolio_values, benchmark_values) if benchmark_values is not None else 0.0,
            up_capture=self._up_capture(returns, benchmark_values) if benchmark_values is not None else 0.0,
            down_capture=self._down_capture(returns, benchmark_values) if benchmark_values is not None else 0.0,

            # Statistical tests
            return_ttest_pvalue=self._return_ttest(returns),
            returns_normality_pvalue=self._normality_test(returns)
        )

    # Return Metrics
    def _total_return(self, values: pd.Series) -> float:
        """Calculate total return"""
        return float((values.iloc[-1] / values.iloc[0]) - 1)

    def _cagr(self, values: pd.Series) -> float:
        """Calculate Compound Annual Growth Rate"""
        total_return = self._total_return(values)
        days = (values.index[-1] - values.index[0]).days
        years = days / 365.25

        if years == 0:
            return 0.0

        return float((1 + total_return) ** (1 / years) - 1)

    def _monthly_returns(self, returns: pd.Series) -> List[float]:
        """Calculate monthly returns"""
        monthly = returns.resample('M').apply(lambda x: (1 + x).prod() - 1)
        return monthly.tolist()

    def _yearly_returns(self, returns: pd.Series) -> List[float]:
        """Calculate yearly returns"""
        yearly = returns.resample('Y').apply(lambda x: (1 + x).prod() - 1)
        return yearly.tolist()

    def _best_month(self, returns: pd.Series) -> float:
        """Best monthly return"""
        monthly = returns.resample('M').apply(lambda x: (1 + x).prod() - 1)
        return float(monthly.max())

    def _worst_month(self, returns: pd.Series) -> float:
        """Worst monthly return"""
        monthly = returns.resample('M').apply(lambda x: (1 + x).prod() - 1)
        return float(monthly.min())

    def _positive_months_pct(self, returns: pd.Series) -> float:
        """Percentage of positive months"""
        monthly = returns.resample('M').apply(lambda x: (1 + x).prod() - 1)
        return float((monthly > 0).sum() / len(monthly))

    # Risk Metrics
    def _volatility(self, returns: pd.Series) -> float:
        """Annualized volatility"""
        return float(returns.std() * np.sqrt(252))

    def _downside_deviation(self, returns: pd.Series, target: float = 0.0) -> float:
        """Annualized downside deviation"""
        downside_returns = returns[returns < target]
        return float(downside_returns.std() * np.sqrt(252))

    def _max_drawdown(self, values: pd.Series) -> float:
        """Maximum drawdown"""
        running_max = values.expanding().max()
        drawdown = (values - running_max) / running_max
        return float(drawdown.min())

    def _max_drawdown_duration(self, values: pd.Series) -> int:
        """Maximum drawdown duration in days"""
        running_max = values.expanding().max()
        drawdown = (values - running_max) / running_max

        # Find all drawdown periods
        in_drawdown = drawdown < 0
        drawdown_periods = []
        start = None

        for i, (date, is_dd) in enumerate(in_drawdown.items()):
            if is_dd and start is None:
                start = date
            elif not is_dd and start is not None:
                drawdown_periods.append((date - start).days)
                start = None

        # If still in drawdown at end
        if start is not None:
            drawdown_periods.append((values.index[-1] - start).days)

        return max(drawdown_periods) if drawdown_periods else 0

    def _value_at_risk(self, returns: pd.Series, confidence: float) -> float:
        """Historical Value at Risk"""
        return float(returns.quantile(1 - confidence))

    def _conditional_var(self, returns: pd.Series, confidence: float) -> float:
        """Conditional VaR (Expected Shortfall)"""
        var = self._value_at_risk(returns, confidence)
        return float(returns[returns <= var].mean())

    # Risk-Adjusted Metrics
    def _sharpe_ratio(self, returns: pd.Series) -> float:
        """Annualized Sharpe Ratio"""
        excess_returns = returns - (self.risk_free_rate / 252)
        if returns.std() == 0:
            return 0.0
        return float(excess_returns.mean() / returns.std() * np.sqrt(252))

    def _sortino_ratio(self, returns: pd.Series, target: float = 0.0) -> float:
        """Annualized Sortino Ratio"""
        excess_returns = returns - (target / 252)
        downside_dev = self._downside_deviation(returns, target)
        if downside_dev == 0:
            return 0.0
        return float(excess_returns.mean() * 252 / downside_dev)

    def _calmar_ratio(self, values: pd.Series) -> float:
        """Calmar Ratio (CAGR / Max Drawdown)"""
        cagr = self._cagr(values)
        mdd = abs(self._max_drawdown(values))
        if mdd == 0:
            return 0.0
        return float(cagr / mdd)

    # Trade Metrics
    def _win_rate(self, trades: List[Dict]) -> float:
        """Percentage of winning trades"""
        if not trades:
            return 0.0

        # Group trades by symbol to calculate P&L
        winning_trades = 0
        total_closed_trades = 0

        # Simplified: count sells with profit
        # In real implementation, match buys with sells
        return 0.5  # Placeholder

    def _profit_loss_ratio(self, trades: List[Dict]) -> float:
        """Average win / Average loss"""
        avg_win = self._avg_win(trades)
        avg_loss = abs(self._avg_loss(trades))
        if avg_loss == 0:
            return 0.0
        return avg_win / avg_loss

    def _avg_holding_period(self, trades: List[Dict]) -> float:
        """Average holding period in days"""
        # Calculate from matched buy/sell pairs
        return 30.0  # Placeholder

    def _trades_per_year(self, trades: List[Dict], values: pd.Series) -> float:
        """Average number of trades per year"""
        if not trades:
            return 0.0
        days = (values.index[-1] - values.index[0]).days
        years = days / 365.25
        return len(trades) / years if years > 0 else 0.0

    def _turnover_rate(self, trades: List[Dict], values: pd.Series) -> float:
        """Portfolio turnover rate"""
        # Sum of all trades / average portfolio value
        total_traded = sum(abs(t.get('total_cost', 0)) for t in trades)
        avg_portfolio_value = values.mean()
        return total_traded / avg_portfolio_value if avg_portfolio_value > 0 else 0.0

    def _avg_win(self, trades: List[Dict]) -> float:
        """Average winning trade P&L"""
        return 1000.0  # Placeholder

    def _avg_loss(self, trades: List[Dict]) -> float:
        """Average losing trade P&L"""
        return -500.0  # Placeholder

    def _expectancy(self, trades: List[Dict]) -> float:
        """Expected value per trade"""
        win_rate = self._win_rate(trades)
        avg_win = self._avg_win(trades)
        avg_loss = abs(self._avg_loss(trades))
        return (win_rate * avg_win) - ((1 - win_rate) * avg_loss)

    # Benchmark Comparison
    def _alpha(self, returns: pd.Series, benchmark_returns: pd.Series) -> float:
        """Jensen's Alpha (annualized)"""
        if benchmark_returns is None:
            return 0.0

        # Align dates
        aligned_returns, aligned_benchmark = returns.align(
            benchmark_returns.pct_change().dropna(),
            join='inner'
        )

        beta = self._beta(returns, benchmark_returns)
        portfolio_return = aligned_returns.mean() * 252
        benchmark_return = aligned_benchmark.mean() * 252

        return float(portfolio_return - (self.risk_free_rate + beta * (benchmark_return - self.risk_free_rate)))

    def _beta(self, returns: pd.Series, benchmark_returns: pd.Series) -> float:
        """Market Beta"""
        if benchmark_returns is None:
            return 1.0

        aligned_returns, aligned_benchmark = returns.align(
            benchmark_returns.pct_change().dropna(),
            join='inner'
        )

        covariance = aligned_returns.cov(aligned_benchmark)
        benchmark_variance = aligned_benchmark.var()

        if benchmark_variance == 0:
            return 1.0

        return float(covariance / benchmark_variance)

    def _correlation(self, returns: pd.Series, benchmark_returns: pd.Series) -> float:
        """Correlation with benchmark"""
        if benchmark_returns is None:
            return 0.0

        aligned_returns, aligned_benchmark = returns.align(
            benchmark_returns.pct_change().dropna(),
            join='inner'
        )

        return float(aligned_returns.corr(aligned_benchmark))

    def _tracking_error(self, returns: pd.Series, benchmark_returns: pd.Series) -> float:
        """Tracking error (annualized)"""
        if benchmark_returns is None:
            return 0.0

        aligned_returns, aligned_benchmark = returns.align(
            benchmark_returns.pct_change().dropna(),
            join='inner'
        )

        tracking_diff = aligned_returns - aligned_benchmark
        return float(tracking_diff.std() * np.sqrt(252))

    def _information_ratio(self, returns: pd.Series, benchmark_returns: pd.Series) -> float:
        """Information Ratio"""
        if benchmark_returns is None:
            return 0.0

        aligned_returns, aligned_benchmark = returns.align(
            benchmark_returns.pct_change().dropna(),
            join='inner'
        )

        tracking_diff = aligned_returns - aligned_benchmark
        tracking_error = tracking_diff.std() * np.sqrt(252)

        if tracking_error == 0:
            return 0.0

        active_return = tracking_diff.mean() * 252
        return float(active_return / tracking_error)

    def _outperformance(self, values: pd.Series, benchmark_values: pd.Series) -> float:
        """Total outperformance vs benchmark"""
        if benchmark_values is None:
            return 0.0

        portfolio_return = self._total_return(values)
        benchmark_return = self._total_return(benchmark_values)
        return portfolio_return - benchmark_return

    def _up_capture(self, returns: pd.Series, benchmark_returns: pd.Series) -> float:
        """Up capture ratio"""
        if benchmark_returns is None:
            return 0.0

        aligned_returns, aligned_benchmark = returns.align(
            benchmark_returns.pct_change().dropna(),
            join='inner'
        )

        up_market = aligned_benchmark > 0
        portfolio_up = aligned_returns[up_market].mean()
        benchmark_up = aligned_benchmark[up_market].mean()

        if benchmark_up == 0:
            return 0.0

        return float(portfolio_up / benchmark_up)

    def _down_capture(self, returns: pd.Series, benchmark_returns: pd.Series) -> float:
        """Down capture ratio"""
        if benchmark_returns is None:
            return 0.0

        aligned_returns, aligned_benchmark = returns.align(
            benchmark_returns.pct_change().dropna(),
            join='inner'
        )

        down_market = aligned_benchmark < 0
        portfolio_down = aligned_returns[down_market].mean()
        benchmark_down = aligned_benchmark[down_market].mean()

        if benchmark_down == 0:
            return 0.0

        return float(portfolio_down / benchmark_down)

    # Statistical Tests
    def _return_ttest(self, returns: pd.Series) -> float:
        """T-test for mean return > 0"""
        t_stat, p_value = stats.ttest_1samp(returns, 0)
        return float(p_value)

    def _normality_test(self, returns: pd.Series) -> float:
        """Jarque-Bera normality test"""
        _, p_value = stats.jarque_bera(returns)
        return float(p_value)
```

## Acceptance Criteria

- [ ] All return metrics calculate correctly (total return, CAGR, monthly/yearly returns)
- [ ] Risk metrics are accurate:
  - [ ] Volatility matches manual calculation
  - [ ] Max drawdown identifies correct peak-to-trough
  - [ ] VaR at 95% and 99% confidence levels
- [ ] Risk-adjusted ratios computed correctly:
  - [ ] Sharpe ratio > 1.0 for good strategies
  - [ ] Sortino ratio higher than Sharpe (less downside penalty)
  - [ ] Calmar ratio positive for profitable strategies
- [ ] Trade statistics accurate:
  - [ ] Win rate between 0 and 1
  - [ ] P/L ratio reflects actual trade outcomes
  - [ ] Holding period in days
- [ ] Benchmark comparison metrics:
  - [ ] Alpha and Beta calculated correctly
  - [ ] Information ratio matches manual calculation
  - [ ] Correlation between -1 and 1
- [ ] Statistical tests return valid p-values (0 to 1)
- [ ] Performance: Metrics calculation for 5-year backtest < 2 seconds
- [ ] Edge cases handled gracefully (zero trades, flat returns, missing benchmark)

## Testing Strategy

### Unit Tests

```python
# tests/services/backtesting/test_metrics_calculator.py
import pytest
import numpy as np
import pandas as pd
from datetime import date, timedelta
from app.services.backtesting.metrics_calculator import MetricsCalculator

class TestMetricsCalculator:
    def test_total_return(self):
        """Test total return calculation"""
        calc = MetricsCalculator()

        dates = pd.date_range('2024-01-01', periods=252, freq='D')
        values = pd.Series(
            [10000 * (1.001 ** i) for i in range(252)],
            index=dates
        )

        total_return = calc._total_return(values)
        expected = (values.iloc[-1] / values.iloc[0]) - 1

        assert abs(total_return - expected) < 1e-6

    def test_sharpe_ratio(self):
        """Test Sharpe ratio calculation"""
        calc = MetricsCalculator(risk_free_rate=0.03)

        # Generate returns with known properties
        np.random.seed(42)
        returns = pd.Series(
            np.random.normal(0.001, 0.01, 252),
            index=pd.date_range('2024-01-01', periods=252, freq='D')
        )

        sharpe = calc._sharpe_ratio(returns)

        # Sharpe should be reasonable for random positive returns
        assert -3 < sharpe < 3

    def test_max_drawdown(self):
        """Test max drawdown calculation"""
        calc = MetricsCalculator()

        # Create series with known drawdown
        values = pd.Series(
            [100, 110, 120, 90, 80, 100, 110],  # 33% drawdown from 120 to 80
            index=pd.date_range('2024-01-01', periods=7, freq='D')
        )

        mdd = calc._max_drawdown(values)
        expected_mdd = (80 - 120) / 120  # -0.333

        assert abs(mdd - expected_mdd) < 1e-6

    def test_beta_calculation(self):
        """Test beta calculation"""
        calc = MetricsCalculator()

        dates = pd.date_range('2024-01-01', periods=252, freq='D')

        # Portfolio with 1.5x market sensitivity
        market_returns = pd.Series(
            np.random.normal(0.0005, 0.01, 252),
            index=dates
        )
        portfolio_returns = market_returns * 1.5
        market_values = pd.Series(
            (1 + market_returns).cumprod() * 100,
            index=dates
        )

        beta = calc._beta(portfolio_returns, market_values)

        # Beta should be close to 1.5
        assert 1.3 < beta < 1.7
```

### Integration Tests

- [ ] Full metrics calculation with real backtest data
  - [ ] Verify all metrics populate correctly
  - [ ] Check metric relationships (e.g., Sortino > Sharpe)
- [ ] Benchmark comparison with real market data
  - [ ] Verify alpha and beta accuracy
  - [ ] Compare with manual calculations
- [ ] Edge case testing
  - [ ] Zero trades scenario
  - [ ] Flat portfolio (no returns)
  - [ ] Extreme volatility

### Performance Tests

- [ ] Metrics calculation speed benchmarks
  - [ ] 1-year backtest: < 500ms
  - [ ] 5-year backtest: < 2 seconds
  - [ ] 10-year backtest: < 5 seconds

## Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Incorrect metric formulas | Low | High | Extensive unit tests, compare with industry tools (QuantStats) |
| Numerical instability (division by zero) | Medium | Medium | Add checks for zero denominators, return 0 or NaN appropriately |
| Benchmark data alignment issues | Medium | Medium | Robust date alignment logic, handle missing data |
| Performance degradation on large datasets | Low | Medium | Optimize pandas operations, use vectorization |
| Statistical test misinterpretation | Low | Medium | Clear documentation, include confidence intervals |

## Performance Requirements

- **Calculation Speed**:
  - 1-year backtest (252 days): < 500ms
  - 5-year backtest (1260 days): < 2 seconds
  - 10-year backtest (2520 days): < 5 seconds

- **Memory Usage**:
  - < 100MB for typical backtest
  - Efficient pandas operations (avoid copies)

- **Accuracy**:
  - Floating-point precision to 6 decimal places
  - Match industry-standard calculations (verified against QuantStats, PyPortfolioOpt)

## Security Considerations

- [ ] No user input directly into calculations (all validated upstream)
- [ ] Sanitize any external benchmark data
- [ ] Rate limit metrics calculation API calls
- [ ] Log all metric calculations for audit trail

## Error Handling

```python
class MetricsCalculator:
    def calculate_all_metrics(self, ...) -> BacktestMetrics:
        """Calculate metrics with comprehensive error handling"""
        try:
            # Validate inputs
            if portfolio_values.empty:
                raise ValueError("Portfolio values cannot be empty")

            if len(portfolio_values) < 2:
                raise ValueError("Need at least 2 data points for metrics")

            # Calculate returns
            returns = portfolio_values.pct_change().dropna()

            # Handle inf/nan returns
            if returns.isin([np.inf, -np.inf]).any():
                logger.warning("Infinite returns detected, replacing with 0")
                returns = returns.replace([np.inf, -np.inf], 0)

            # Proceed with calculations
            metrics = BacktestMetrics(...)

            return metrics

        except ValueError as e:
            logger.error(f"Invalid input for metrics calculation: {e}")
            raise HTTPException(status_code=400, detail=str(e))
        except Exception as e:
            logger.exception("Unexpected error calculating metrics")
            raise HTTPException(
                status_code=500,
                detail="Failed to calculate performance metrics"
            )

    def _sharpe_ratio(self, returns: pd.Series) -> float:
        """Sharpe ratio with error handling"""
        try:
            if returns.std() == 0:
                logger.warning("Zero volatility, returning 0 for Sharpe ratio")
                return 0.0

            excess_returns = returns - (self.risk_free_rate / 252)
            return float(excess_returns.mean() / returns.std() * np.sqrt(252))
        except Exception as e:
            logger.error(f"Error calculating Sharpe ratio: {e}")
            return 0.0
```

## Dependencies

- **Depends on**:
  - BT-001a: Backtesting Simulation Engine (provides portfolio values and trades)
  - BT-001b: Backtesting Data & Storage (provides benchmark data)

- **External Libraries**:
  - numpy: Numerical calculations
  - pandas: Time series operations
  - scipy: Statistical tests

- **Blocks**: BT-003, BT-004b

## References

- [IMPROVEMENT_TICKETS.md](../../IMPROVEMENT_TICKETS.md) - Epic 2: Backtesting Engine
- **SRS.md**: Section 3.2.3 Performance Metrics Requirements
- **SDS.md**: Section 5.3 Backtesting Architecture
- [QuantStats Documentation](https://github.com/ranaroussi/quantstats)
- [PyPortfolioOpt Metrics](https://pyportfolioopt.readthedocs.io/)
- [Investopedia - Sharpe Ratio](https://www.investopedia.com/terms/s/sharperatio.asp)
- [Maximum Drawdown](https://www.investopedia.com/terms/m/maximum-drawdown-mdd.asp)

## Progress

- **0%** - Not started

## Notes

- Use industry-standard formulas for all metrics (verify against QuantStats)
- Handle edge cases gracefully (zero volatility, missing benchmark, etc.)
- Annualize metrics consistently (252 trading days per year)
- Consider adding more advanced metrics in future: Omega ratio, Kappa ratio
- Future enhancement: Monte Carlo simulation for confidence intervals
- Future enhancement: Rolling metrics (rolling Sharpe, rolling beta)
- Document all formula assumptions clearly in code comments
