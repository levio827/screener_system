# BT-003: Backtesting API Endpoints

## Metadata

| Field | Value |
|-------|-------|
| **ID** | BT-003 |
| **Title** | Create Backtesting REST API |
| **Type** | Feature |
| **Status** | BACKLOG |
| **Priority** | P0 (Critical) |
| **Estimate** | 8 hours |
| **Sprint** | Sprint 5 |
| **Epic** | Backtesting Engine |
| **Assignee** | TBD |
| **Depends On** | BT-001b, BT-002 |
| **Blocks** | BT-004a, BT-004b |
| **Created** | 2025-11-29 |
| **Updated** | 2025-11-30 |
| **Tags** | `api`, `backend`, `fastapi`, `websocket`, `async`, `job-queue` |

## Description

Implement comprehensive REST API endpoints for backtesting features, including async job processing for long-running backtests and WebSocket support for real-time progress updates. The API will handle backtest execution, result retrieval, trade history queries, and historical backtest management with proper rate limiting and authentication.

## Acceptance Criteria

- [ ] **Core Endpoints**
  - [ ] `POST /v1/backtest` - Submit backtest job
    - [ ] Request validation (parameters, date ranges)
    - [ ] Async job creation with task ID
    - [ ] Rate limit enforcement per tier
  - [ ] `GET /v1/backtest/{id}` - Get backtest status and results
    - [ ] Return job status (pending/running/completed/failed)
    - [ ] Include performance metrics when completed
  - [ ] `GET /v1/backtest/{id}/trades` - Query detailed trade history
    - [ ] Pagination support (limit, offset)
    - [ ] Filtering by date range, symbol
  - [ ] `GET /v1/backtest/{id}/chart` - Return chart data
    - [ ] Equity curve data
    - [ ] Drawdown series
    - [ ] Benchmark comparison
  - [ ] `GET /v1/backtest/history` - User backtest history
    - [ ] Pagination and sorting
    - [ ] Filter by status, date range
  - [ ] `DELETE /v1/backtest/{id}` - Cancel/delete backtest
- [ ] **WebSocket Endpoint**
  - [ ] `WS /v1/backtest/{id}/progress` - Real-time progress updates
    - [ ] Progress percentage (0-100)
    - [ ] Current processing date
    - [ ] Estimated time remaining
- [ ] **Rate Limiting**
  - [ ] Free tier: 10 requests/hour
  - [ ] Pro tier: 100 requests/hour
  - [ ] Return 429 with Retry-After header
- [ ] **Documentation**
  - [ ] OpenAPI 3.0 spec generation
  - [ ] Interactive Swagger UI
  - [ ] Example requests/responses

## Subtasks

### 1. Project Setup and Dependencies
- [ ] Setup FastAPI application structure
  - [ ] Create `app/api/v1/endpoints/backtest.py`
  - [ ] Configure CORS and middleware
  - [ ] Setup dependency injection
- [ ] Install required packages
  - [ ] `fastapi[all]>=0.104.0` - Web framework
  - [ ] `celery>=5.3.0` - Async task queue
  - [ ] `redis>=5.0.0` - Task broker and rate limiting
  - [ ] `websockets>=12.0` - WebSocket support
  - [ ] `slowapi>=0.1.9` - Rate limiting
- [ ] Configure Celery worker
  - [ ] Setup Redis broker connection
  - [ ] Configure task serialization
  - [ ] Set concurrency and prefetch settings

### 2. Request/Response Models
- [ ] Define Pydantic models
  - [ ] `BacktestRequest` - Input validation
    - [ ] Strategy ID or filter criteria
    - [ ] Date range (start_date, end_date)
    - [ ] Initial capital (min: 1000, max: 10M)
    - [ ] Rebalancing frequency (daily/weekly/monthly)
    - [ ] Transaction costs (commission, slippage)
    - [ ] Benchmark symbol (optional)
  - [ ] `BacktestResponse` - Job creation
    - [ ] Task ID (UUID)
    - [ ] Status (pending)
    - [ ] Created timestamp
  - [ ] `BacktestResult` - Complete results
    - [ ] Performance metrics (from BT-002)
    - [ ] Equity curve data
    - [ ] Trade count, win rate
  - [ ] `BacktestStatus` - Job status
    - [ ] Status enum (pending/running/completed/failed)
    - [ ] Progress percentage
    - [ ] Error message (if failed)
  - [ ] `TradeHistory` - Trade details
    - [ ] Symbol, entry/exit dates
    - [ ] Prices, quantities, PnL
  - [ ] `ChartData` - Visualization data
    - [ ] Time series for equity, drawdown
    - [ ] Benchmark comparison

### 3. API Endpoint Implementation
- [ ] POST `/v1/backtest` - Create backtest job
  - [ ] Validate request data
  - [ ] Check user rate limits
  - [ ] Create Celery task
  - [ ] Store job metadata in database
  - [ ] Return task ID and status
- [ ] GET `/v1/backtest/{id}` - Get backtest results
  - [ ] Verify user ownership
  - [ ] Query job status from Celery
  - [ ] Fetch results from database if completed
  - [ ] Handle not found errors
- [ ] GET `/v1/backtest/{id}/trades` - Get trade history
  - [ ] Implement pagination (default: 50 per page)
  - [ ] Support filtering (date range, symbol)
  - [ ] Return total count for pagination
- [ ] GET `/v1/backtest/{id}/chart` - Get chart data
  - [ ] Fetch equity curve from storage
  - [ ] Calculate drawdown series
  - [ ] Include benchmark if specified
  - [ ] Optimize data size (sampling for large datasets)
- [ ] GET `/v1/backtest/history` - List user backtests
  - [ ] Query user's backtest jobs
  - [ ] Implement pagination and sorting
  - [ ] Filter by status, date range
- [ ] DELETE `/v1/backtest/{id}` - Cancel/delete backtest
  - [ ] Check job status
  - [ ] Revoke Celery task if running
  - [ ] Mark as cancelled in database

### 4. WebSocket Implementation
- [ ] Setup WebSocket endpoint
  - [ ] `WS /v1/backtest/{id}/progress`
  - [ ] Authenticate connection
  - [ ] Verify user ownership
- [ ] Implement progress broadcasting
  - [ ] Subscribe to Redis pub/sub channel
  - [ ] Send progress updates to client
  - [ ] Handle disconnect and reconnect
  - [ ] Close connection on completion/failure
- [ ] Progress message format
  - [ ] Status (running/completed/failed)
  - [ ] Progress percentage (0-100)
  - [ ] Current processing date
  - [ ] Estimated time remaining
  - [ ] Partial metrics (trades executed so far)

### 5. Async Job Processing
- [ ] Create Celery task `run_backtest_task`
  - [ ] Accept backtest configuration
  - [ ] Initialize backtesting engine (from BT-001a)
  - [ ] Load historical data (from BT-001b)
  - [ ] Execute backtest simulation
  - [ ] Calculate performance metrics (from BT-002)
  - [ ] Store results in database
  - [ ] Update task status
- [ ] Implement progress tracking
  - [ ] Publish progress to Redis channel
  - [ ] Update percentage based on date processed
  - [ ] Calculate ETA from processing speed
- [ ] Error handling
  - [ ] Catch and log exceptions
  - [ ] Store error details
  - [ ] Update task status to failed
  - [ ] Send failure notification via WebSocket

### 6. Rate Limiting
- [ ] Implement rate limiter
  - [ ] Use SlowAPI with Redis backend
  - [ ] Define rate limit decorators
    - [ ] Free tier: `@limiter.limit("10/hour")`
    - [ ] Pro tier: `@limiter.limit("100/hour")`
  - [ ] Check user tier from database
- [ ] Rate limit response handling
  - [ ] Return 429 status code
  - [ ] Include Retry-After header
  - [ ] Provide clear error message
- [ ] Rate limit bypass for admins
  - [ ] Whitelist admin users
  - [ ] Unlimited quota for testing

### 7. API Documentation
- [ ] Configure OpenAPI generation
  - [ ] Add endpoint descriptions
  - [ ] Document all parameters
  - [ ] Provide example values
  - [ ] Define error responses
- [ ] Setup Swagger UI
  - [ ] Enable at `/docs`
  - [ ] Add authentication support
  - [ ] Include example requests
- [ ] Create ReDoc documentation
  - [ ] Enable at `/redoc`
  - [ ] Enhanced readability

### 8. Testing and Validation
- [ ] Unit tests
  - [ ] Test request validation
  - [ ] Test response serialization
  - [ ] Test error handling
- [ ] Integration tests
  - [ ] Test full backtest flow
  - [ ] Test WebSocket connection
  - [ ] Test rate limiting
  - [ ] Test pagination
- [ ] Load testing
  - [ ] Concurrent backtest requests
  - [ ] WebSocket connections
  - [ ] Rate limit verification

## Implementation Details

### FastAPI Endpoint Structure

```python
# app/api/v1/endpoints/backtest.py
from fastapi import APIRouter, Depends, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse
from slowapi import Limiter
from slowapi.util import get_remote_address
from celery.result import AsyncResult
from typing import Optional, List
import uuid

from app.core.security import get_current_user
from app.core.config import settings
from app.models.backtest import (
    BacktestRequest, BacktestResponse, BacktestResult,
    BacktestStatus, TradeHistory, ChartData, BacktestHistoryItem
)
from app.tasks.backtest import run_backtest_task
from app.services.backtest_service import BacktestService
from app.core.rate_limit import get_user_rate_limit

router = APIRouter(prefix="/v1/backtest", tags=["backtest"])
limiter = Limiter(key_func=get_remote_address)

@router.post("", response_model=BacktestResponse)
async def create_backtest(
    request: BacktestRequest,
    current_user = Depends(get_current_user),
    backtest_service: BacktestService = Depends()
):
    """
    Submit a new backtest job.

    Rate Limits:
    - Free tier: 10 requests/hour
    - Pro tier: 100 requests/hour

    Returns:
        BacktestResponse with task_id for tracking progress
    """
    # Apply rate limiting based on user tier
    rate_limit = get_user_rate_limit(current_user)
    limiter.limit(rate_limit)(lambda: None)()

    # Validate request
    if request.start_date >= request.end_date:
        raise HTTPException(status_code=400, detail="start_date must be before end_date")

    if request.initial_capital < 1000 or request.initial_capital > 10_000_000:
        raise HTTPException(status_code=400, detail="initial_capital must be between 1,000 and 10,000,000")

    # Create task ID
    task_id = str(uuid.uuid4())

    # Store job metadata
    await backtest_service.create_job(
        task_id=task_id,
        user_id=current_user.id,
        config=request.dict()
    )

    # Submit Celery task
    task = run_backtest_task.apply_async(
        args=[task_id, current_user.id, request.dict()],
        task_id=task_id
    )

    return BacktestResponse(
        task_id=task_id,
        status="pending",
        created_at=datetime.utcnow()
    )

@router.get("/{task_id}", response_model=BacktestStatus)
async def get_backtest_status(
    task_id: str,
    current_user = Depends(get_current_user),
    backtest_service: BacktestService = Depends()
):
    """
    Get backtest job status and results if completed.
    """
    # Verify ownership
    job = await backtest_service.get_job(task_id)
    if not job or job.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Backtest not found")

    # Get Celery task status
    task_result = AsyncResult(task_id)

    if task_result.state == "PENDING":
        return BacktestStatus(status="pending", progress=0)
    elif task_result.state == "STARTED":
        progress = task_result.info.get("progress", 0) if task_result.info else 0
        return BacktestStatus(status="running", progress=progress)
    elif task_result.state == "SUCCESS":
        result = await backtest_service.get_result(task_id)
        return BacktestStatus(status="completed", progress=100, result=result)
    elif task_result.state == "FAILURE":
        error = str(task_result.info) if task_result.info else "Unknown error"
        return BacktestStatus(status="failed", error=error)

    return BacktestStatus(status="unknown")

@router.get("/{task_id}/trades", response_model=List[TradeHistory])
async def get_backtest_trades(
    task_id: str,
    limit: int = 50,
    offset: int = 0,
    symbol: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    current_user = Depends(get_current_user),
    backtest_service: BacktestService = Depends()
):
    """
    Get detailed trade history from a completed backtest.

    Supports pagination and filtering.
    """
    # Verify ownership
    job = await backtest_service.get_job(task_id)
    if not job or job.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Backtest not found")

    # Check if completed
    if job.status != "completed":
        raise HTTPException(status_code=400, detail="Backtest not completed")

    # Fetch trades with filters
    trades = await backtest_service.get_trades(
        task_id=task_id,
        limit=limit,
        offset=offset,
        symbol=symbol,
        start_date=start_date,
        end_date=end_date
    )

    return trades

@router.get("/{task_id}/chart", response_model=ChartData)
async def get_backtest_chart_data(
    task_id: str,
    current_user = Depends(get_current_user),
    backtest_service: BacktestService = Depends()
):
    """
    Get chart data for visualization (equity curve, drawdown, benchmark).
    """
    # Verify ownership
    job = await backtest_service.get_job(task_id)
    if not job or job.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Backtest not found")

    # Check if completed
    if job.status != "completed":
        raise HTTPException(status_code=400, detail="Backtest not completed")

    # Fetch chart data
    chart_data = await backtest_service.get_chart_data(task_id)

    return chart_data

@router.get("", response_model=List[BacktestHistoryItem])
async def get_backtest_history(
    limit: int = 20,
    offset: int = 0,
    status: Optional[str] = None,
    current_user = Depends(get_current_user),
    backtest_service: BacktestService = Depends()
):
    """
    Get user's backtest history with pagination and filtering.
    """
    history = await backtest_service.get_user_history(
        user_id=current_user.id,
        limit=limit,
        offset=offset,
        status=status
    )

    return history

@router.delete("/{task_id}")
async def cancel_backtest(
    task_id: str,
    current_user = Depends(get_current_user),
    backtest_service: BacktestService = Depends()
):
    """
    Cancel a running backtest or delete a completed one.
    """
    # Verify ownership
    job = await backtest_service.get_job(task_id)
    if not job or job.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Backtest not found")

    # Revoke Celery task if running
    if job.status in ["pending", "running"]:
        from app.core.celery_app import celery_app
        celery_app.control.revoke(task_id, terminate=True)

    # Mark as cancelled
    await backtest_service.cancel_job(task_id)

    return {"message": "Backtest cancelled successfully"}

@router.websocket("/{task_id}/progress")
async def backtest_progress_websocket(
    websocket: WebSocket,
    task_id: str,
    token: str,  # Pass JWT token as query parameter
    backtest_service: BacktestService = Depends()
):
    """
    WebSocket endpoint for real-time backtest progress updates.

    Connect with: ws://host/v1/backtest/{task_id}/progress?token=JWT_TOKEN
    """
    # Authenticate
    try:
        user = await authenticate_websocket(token)
    except Exception:
        await websocket.close(code=4001, reason="Unauthorized")
        return

    # Verify ownership
    job = await backtest_service.get_job(task_id)
    if not job or job.user_id != user.id:
        await websocket.close(code=4004, reason="Not found")
        return

    await websocket.accept()

    try:
        # Subscribe to Redis pub/sub for progress updates
        import aioredis
        redis = await aioredis.create_redis_pool(settings.REDIS_URL)
        channel = f"backtest:progress:{task_id}"

        ch = (await redis.subscribe(channel))[0]

        # Send initial status
        task_result = AsyncResult(task_id)
        await websocket.send_json({
            "status": task_result.state.lower(),
            "progress": 0
        })

        # Listen for updates
        while await ch.wait_message():
            message = await ch.get_json()
            await websocket.send_json(message)

            # Close if completed or failed
            if message.get("status") in ["completed", "failed"]:
                break

        redis.close()
        await redis.wait_closed()

    except WebSocketDisconnect:
        pass
    finally:
        await websocket.close()
```

### Celery Task Implementation

```python
# app/tasks/backtest.py
from celery import Task
from app.core.celery_app import celery_app
from app.services.backtesting_engine import BacktestingEngine
from app.services.data_loader import DataLoader
from app.services.metrics_calculator import MetricsCalculator
from app.services.backtest_service import BacktestService
import aioredis
import asyncio
from datetime import datetime

class ProgressTask(Task):
    """Base task with progress tracking."""

    def __init__(self):
        self.redis_pool = None

    async def publish_progress(self, task_id: str, data: dict):
        """Publish progress update to Redis."""
        if not self.redis_pool:
            self.redis_pool = await aioredis.create_redis_pool(settings.REDIS_URL)

        channel = f"backtest:progress:{task_id}"
        await self.redis_pool.publish_json(channel, data)

@celery_app.task(bind=True, base=ProgressTask, name="run_backtest")
def run_backtest_task(self, task_id: str, user_id: int, config: dict):
    """
    Execute backtest simulation asynchronously.

    Publishes progress updates via Redis pub/sub.
    """
    try:
        # Update status to running
        self.update_state(
            state="STARTED",
            meta={"progress": 0, "status": "Initializing..."}
        )

        # Initialize services
        engine = BacktestingEngine()
        data_loader = DataLoader()
        metrics_calc = MetricsCalculator()
        backtest_service = BacktestService()

        # Load historical data
        asyncio.run(self.publish_progress(task_id, {
            "status": "running",
            "progress": 5,
            "message": "Loading historical data..."
        }))

        historical_data = data_loader.load_data(
            start_date=config["start_date"],
            end_date=config["end_date"],
            symbols=config.get("symbols", [])
        )

        # Configure engine
        asyncio.run(self.publish_progress(task_id, {
            "status": "running",
            "progress": 10,
            "message": "Configuring backtest..."
        }))

        engine.configure(
            initial_capital=config["initial_capital"],
            commission=config.get("commission", 0.001),
            slippage=config.get("slippage", 0.0005),
            rebalancing=config.get("rebalancing", "monthly")
        )

        # Run simulation with progress tracking
        total_days = (config["end_date"] - config["start_date"]).days

        for idx, date in enumerate(engine.date_range):
            # Process trades for this date
            engine.process_date(date)

            # Update progress every 1% or daily if < 100 days
            if idx % max(1, total_days // 100) == 0:
                progress = 10 + int((idx / total_days) * 80)  # 10-90%

                asyncio.run(self.publish_progress(task_id, {
                    "status": "running",
                    "progress": progress,
                    "message": f"Processing {date.strftime('%Y-%m-%d')}",
                    "current_date": date.isoformat(),
                    "trades_executed": len(engine.trades)
                }))

        # Calculate performance metrics
        asyncio.run(self.publish_progress(task_id, {
            "status": "running",
            "progress": 90,
            "message": "Calculating metrics..."
        }))

        results = engine.get_results()
        metrics = metrics_calc.calculate_all_metrics(
            returns=results["returns"],
            benchmark_returns=results.get("benchmark_returns"),
            trades=results["trades"]
        )

        # Store results in database
        asyncio.run(self.publish_progress(task_id, {
            "status": "running",
            "progress": 95,
            "message": "Storing results..."
        }))

        asyncio.run(backtest_service.store_result(
            task_id=task_id,
            results=results,
            metrics=metrics
        ))

        # Publish completion
        asyncio.run(self.publish_progress(task_id, {
            "status": "completed",
            "progress": 100,
            "message": "Backtest completed successfully"
        }))

        return {
            "status": "success",
            "metrics": metrics,
            "trades_count": len(results["trades"])
        }

    except Exception as e:
        # Publish failure
        asyncio.run(self.publish_progress(task_id, {
            "status": "failed",
            "error": str(e)
        }))

        # Store error
        asyncio.run(backtest_service.mark_failed(task_id, str(e)))

        raise
```

### Request/Response Models

```python
# app/models/backtest.py
from pydantic import BaseModel, Field, validator
from datetime import date, datetime
from typing import Optional, List, Dict
from enum import Enum

class RebalancingFrequency(str, Enum):
    DAILY = "daily"
    WEEKLY = "weekly"
    MONTHLY = "monthly"
    QUARTERLY = "quarterly"

class BacktestStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class BacktestRequest(BaseModel):
    """Request model for creating a backtest."""
    strategy_id: Optional[int] = Field(None, description="Predefined strategy ID")
    filter_criteria: Optional[Dict] = Field(None, description="Custom filter criteria")
    start_date: date = Field(..., description="Backtest start date")
    end_date: date = Field(..., description="Backtest end date")
    initial_capital: float = Field(100000, ge=1000, le=10000000, description="Initial capital")
    rebalancing: RebalancingFrequency = Field(RebalancingFrequency.MONTHLY)
    commission: float = Field(0.001, ge=0, le=0.1, description="Commission rate")
    slippage: float = Field(0.0005, ge=0, le=0.05, description="Slippage rate")
    benchmark: Optional[str] = Field(None, description="Benchmark symbol (e.g., SPY, ^GSPC)")

    @validator("end_date")
    def validate_date_range(cls, v, values):
        if "start_date" in values and v <= values["start_date"]:
            raise ValueError("end_date must be after start_date")
        return v

class BacktestResponse(BaseModel):
    """Response model for backtest creation."""
    task_id: str
    status: BacktestStatus
    created_at: datetime

class PerformanceMetrics(BaseModel):
    """Performance metrics from completed backtest."""
    total_return: float
    cagr: float
    sharpe_ratio: float
    sortino_ratio: float
    max_drawdown: float
    win_rate: float
    profit_factor: float
    total_trades: int

class BacktestResult(BaseModel):
    """Complete backtest results."""
    task_id: str
    status: BacktestStatus
    progress: int = Field(ge=0, le=100)
    metrics: Optional[PerformanceMetrics] = None
    created_at: datetime
    completed_at: Optional[datetime] = None
    error: Optional[str] = None

class TradeHistory(BaseModel):
    """Individual trade details."""
    symbol: str
    entry_date: date
    entry_price: float
    exit_date: Optional[date] = None
    exit_price: Optional[float] = None
    quantity: int
    pnl: Optional[float] = None
    pnl_percent: Optional[float] = None

class EquityPoint(BaseModel):
    """Single point in equity curve."""
    date: date
    equity: float
    benchmark: Optional[float] = None

class ChartData(BaseModel):
    """Chart data for visualization."""
    equity_curve: List[EquityPoint]
    drawdown_series: List[Dict[str, float]]
    monthly_returns: Dict[str, float]

class BacktestHistoryItem(BaseModel):
    """Summary item in backtest history list."""
    task_id: str
    status: BacktestStatus
    created_at: datetime
    completed_at: Optional[datetime] = None
    total_return: Optional[float] = None
    sharpe_ratio: Optional[float] = None
```

## Testing Strategy

### Unit Tests

```python
# tests/api/test_backtest_endpoints.py
import pytest
from fastapi.testclient import TestClient
from unittest.mock import Mock, patch
from datetime import date

def test_create_backtest_success(client: TestClient, auth_headers):
    """Test successful backtest creation."""
    request_data = {
        "start_date": "2020-01-01",
        "end_date": "2023-12-31",
        "initial_capital": 100000,
        "rebalancing": "monthly"
    }

    response = client.post("/v1/backtest", json=request_data, headers=auth_headers)

    assert response.status_code == 200
    assert "task_id" in response.json()
    assert response.json()["status"] == "pending"

def test_create_backtest_invalid_dates(client: TestClient, auth_headers):
    """Test backtest creation with invalid date range."""
    request_data = {
        "start_date": "2023-12-31",
        "end_date": "2020-01-01",  # Before start_date
        "initial_capital": 100000
    }

    response = client.post("/v1/backtest", json=request_data, headers=auth_headers)

    assert response.status_code == 400

def test_create_backtest_rate_limit(client: TestClient, auth_headers):
    """Test rate limiting enforcement."""
    request_data = {
        "start_date": "2020-01-01",
        "end_date": "2023-12-31",
        "initial_capital": 100000
    }

    # Make requests until rate limit
    for _ in range(11):  # Free tier: 10/hour
        response = client.post("/v1/backtest", json=request_data, headers=auth_headers)

    assert response.status_code == 429
    assert "Retry-After" in response.headers

def test_get_backtest_status_not_found(client: TestClient, auth_headers):
    """Test getting status of non-existent backtest."""
    response = client.get("/v1/backtest/invalid-id", headers=auth_headers)

    assert response.status_code == 404

def test_get_trades_pagination(client: TestClient, auth_headers, completed_backtest):
    """Test trade history pagination."""
    task_id = completed_backtest["task_id"]

    # First page
    response = client.get(
        f"/v1/backtest/{task_id}/trades?limit=10&offset=0",
        headers=auth_headers
    )
    assert response.status_code == 200
    assert len(response.json()) <= 10

    # Second page
    response = client.get(
        f"/v1/backtest/{task_id}/trades?limit=10&offset=10",
        headers=auth_headers
    )
    assert response.status_code == 200
```

### Integration Tests

```python
# tests/integration/test_backtest_flow.py
import pytest
import asyncio
from datetime import date

@pytest.mark.integration
async def test_full_backtest_workflow(client, auth_headers, celery_worker):
    """Test complete backtest workflow from creation to results."""
    # Create backtest
    request_data = {
        "start_date": "2023-01-01",
        "end_date": "2023-12-31",
        "initial_capital": 100000,
        "rebalancing": "monthly"
    }

    response = client.post("/v1/backtest", json=request_data, headers=auth_headers)
    assert response.status_code == 200
    task_id = response.json()["task_id"]

    # Wait for completion (with timeout)
    for _ in range(30):  # 30 seconds timeout
        await asyncio.sleep(1)

        status_response = client.get(f"/v1/backtest/{task_id}", headers=auth_headers)
        status = status_response.json()["status"]

        if status in ["completed", "failed"]:
            break

    assert status == "completed"

    # Get results
    result = status_response.json()
    assert result["metrics"] is not None
    assert "total_return" in result["metrics"]

    # Get trades
    trades_response = client.get(f"/v1/backtest/{task_id}/trades", headers=auth_headers)
    assert trades_response.status_code == 200

    # Get chart data
    chart_response = client.get(f"/v1/backtest/{task_id}/chart", headers=auth_headers)
    assert chart_response.status_code == 200
    assert "equity_curve" in chart_response.json()

@pytest.mark.integration
async def test_websocket_progress_updates(client, auth_headers):
    """Test WebSocket real-time progress updates."""
    from websockets import connect

    # Create backtest
    response = client.post("/v1/backtest", json={
        "start_date": "2023-01-01",
        "end_date": "2023-12-31",
        "initial_capital": 100000
    }, headers=auth_headers)

    task_id = response.json()["task_id"]
    token = auth_headers["Authorization"].split(" ")[1]

    # Connect to WebSocket
    async with connect(f"ws://localhost/v1/backtest/{task_id}/progress?token={token}") as websocket:
        progress_updates = []

        async for message in websocket:
            data = json.loads(message)
            progress_updates.append(data)

            if data["status"] in ["completed", "failed"]:
                break

        # Verify progress updates
        assert len(progress_updates) > 0
        assert progress_updates[0]["progress"] >= 0
        assert progress_updates[-1]["status"] in ["completed", "failed"]
```

### Load Tests

```python
# tests/load/test_backtest_load.py
import pytest
from locust import HttpUser, task, between

class BacktestUser(HttpUser):
    wait_time = between(1, 3)

    def on_start(self):
        """Login and get auth token."""
        response = self.client.post("/auth/login", json={
            "username": "test_user",
            "password": "test_pass"
        })
        self.token = response.json()["access_token"]
        self.headers = {"Authorization": f"Bearer {self.token}"}

    @task(3)
    def create_backtest(self):
        """Create backtest (most common operation)."""
        self.client.post("/v1/backtest", json={
            "start_date": "2023-01-01",
            "end_date": "2023-12-31",
            "initial_capital": 100000
        }, headers=self.headers)

    @task(5)
    def check_status(self):
        """Check backtest status."""
        if hasattr(self, "task_id"):
            self.client.get(f"/v1/backtest/{self.task_id}", headers=self.headers)

    @task(1)
    def get_history(self):
        """Get backtest history."""
        self.client.get("/v1/backtest?limit=20", headers=self.headers)

# Run with: locust -f tests/load/test_backtest_load.py --host=http://localhost:8000
```

## Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Long-running backtests timeout | High | Medium | Implement async processing with Celery, set appropriate timeouts (10min default, 1hr max) |
| Memory overflow with large datasets | Medium | High | Implement data streaming, limit date ranges (max 10 years), use chunked processing |
| Redis connection failures | Low | High | Implement connection pooling, retry logic, fallback to database polling |
| WebSocket connection drops | Medium | Medium | Implement reconnection logic on client, resume from last progress |
| Rate limit bypass attempts | Medium | Medium | Use Redis-based distributed rate limiting, monitor for abuse patterns |
| Celery worker crashes | Low | High | Configure worker auto-restart, implement health checks, dead letter queue |
| Database connection pool exhaustion | Medium | High | Configure appropriate pool size, implement connection timeout, query optimization |
| Concurrent access to same backtest | Low | Low | Implement optimistic locking, use transaction isolation |
| API authentication bypass | Low | Critical | Use JWT with short expiration, validate on every request, rate limit by IP |
| Task ID enumeration attacks | Medium | Low | Use UUIDs instead of sequential IDs, verify ownership on all operations |

## Performance Requirements

| Metric | Target | Measurement Method |
|--------|--------|-------------------|
| API response time (sync endpoints) | < 200ms (p95) | APM monitoring, middleware timing |
| Backtest execution time | < 5 min for 3 years daily data | Task duration logging |
| WebSocket latency | < 100ms | Client-side ping/pong measurement |
| Concurrent backtests | 50+ simultaneous | Load testing with Locust |
| Database query time | < 50ms (p95) | Query profiling, slow query log |
| Rate limit check overhead | < 10ms | Redis operation timing |
| Memory usage per worker | < 1GB | Process monitoring |
| API throughput | 1000 req/sec | Load testing |

### Optimization Strategies

1. **Database Optimization**
   - Index on user_id, task_id, created_at
   - Partition trades table by date
   - Use connection pooling (min: 5, max: 20)

2. **Caching**
   - Cache backtest results for 24 hours
   - Cache chart data with Redis
   - Use ETags for conditional requests

3. **Async Processing**
   - Use Celery with 4-8 workers
   - Configure task priorities (high for small backtests)
   - Implement task timeout and retry

4. **Data Transfer Optimization**
   - Compress WebSocket messages
   - Sample equity curve for large datasets (max 1000 points)
   - Paginate trade history (50 per page)

## Security Considerations

### Authentication & Authorization

```python
# Implement JWT-based authentication
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from jose import JWTError, jwt

security = HTTPBearer()

async def get_current_user(
    credentials: HTTPAuthorizationCredentials = Depends(security)
) -> User:
    """Verify JWT token and return current user."""
    try:
        token = credentials.credentials
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=["HS256"])
        user_id = payload.get("sub")

        if user_id is None:
            raise HTTPException(status_code=401, detail="Invalid token")

        user = await get_user_by_id(user_id)
        if user is None:
            raise HTTPException(status_code=401, detail="User not found")

        return user

    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")
```

### Input Validation

- Validate all date ranges (start_date < end_date, not in future)
- Sanitize strategy filter criteria to prevent SQL injection
- Limit initial capital range (1K - 10M)
- Validate commission/slippage rates (0-10%)
- Maximum backtest duration: 10 years
- Whitelist allowed benchmark symbols

### Data Access Control

- Verify user ownership on all GET/DELETE operations
- Implement row-level security in database
- Prevent task ID enumeration with UUIDs
- Log all access attempts for audit

### Rate Limiting

```python
# Implement tiered rate limiting
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

def get_user_rate_limit(user: User) -> str:
    """Get rate limit string based on user tier."""
    if user.tier == "free":
        return "10/hour"
    elif user.tier == "pro":
        return "100/hour"
    elif user.tier == "enterprise":
        return "1000/hour"
    else:
        return "5/hour"  # Default restrictive
```

### Celery Task Security

- Validate all task inputs before processing
- Run workers with limited privileges
- Implement task execution timeout (1 hour max)
- Sanitize error messages (no sensitive data leakage)
- Use signed task messages

### WebSocket Security

- Authenticate WebSocket connections with JWT
- Verify user ownership before sending progress
- Implement connection rate limiting
- Close idle connections after 5 minutes
- Validate all incoming messages

## Error Handling

### API Error Responses

```python
# Standardized error response format
from fastapi import HTTPException
from fastapi.responses import JSONResponse

class BacktestError(Exception):
    """Base exception for backtest errors."""
    pass

class BacktestNotFoundError(BacktestError):
    """Backtest not found."""
    pass

class BacktestValidationError(BacktestError):
    """Invalid backtest configuration."""
    pass

@app.exception_handler(BacktestNotFoundError)
async def backtest_not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={
            "error": "BacktestNotFound",
            "message": str(exc),
            "task_id": getattr(exc, "task_id", None)
        }
    )

@app.exception_handler(BacktestValidationError)
async def backtest_validation_handler(request, exc):
    return JSONResponse(
        status_code=400,
        content={
            "error": "ValidationError",
            "message": str(exc),
            "details": getattr(exc, "details", None)
        }
    )
```

### Error Categories

1. **Client Errors (4xx)**
   - 400: Invalid request (date range, parameters)
   - 401: Unauthorized (invalid/expired token)
   - 403: Forbidden (accessing other user's backtest)
   - 404: Backtest not found
   - 429: Rate limit exceeded

2. **Server Errors (5xx)**
   - 500: Internal server error (unexpected failures)
   - 502: Celery worker unavailable
   - 503: Service temporarily unavailable (maintenance)
   - 504: Backtest timeout

### Retry Strategy

```python
# Configure Celery task retry
@celery_app.task(
    bind=True,
    autoretry_for=(ConnectionError, TimeoutError),
    retry_kwargs={"max_retries": 3, "countdown": 60},
    retry_backoff=True
)
def run_backtest_task(self, task_id, user_id, config):
    """Backtest task with automatic retry on transient failures."""
    pass
```

### Logging

```python
# Structured logging for debugging
import logging
import structlog

logger = structlog.get_logger(__name__)

@router.post("/v1/backtest")
async def create_backtest(request: BacktestRequest, user = Depends(get_current_user)):
    logger.info(
        "backtest_created",
        user_id=user.id,
        start_date=request.start_date,
        end_date=request.end_date,
        initial_capital=request.initial_capital
    )

    try:
        # ... create backtest
        pass
    except Exception as e:
        logger.error(
            "backtest_creation_failed",
            user_id=user.id,
            error=str(e),
            exc_info=True
        )
        raise
```

## Progress

**0% - Not started**

## Notes

### Implementation Priority

1. **Phase 1 (Core API)**: Implement basic CRUD endpoints without WebSocket
2. **Phase 2 (Async Processing)**: Add Celery integration and job queue
3. **Phase 3 (Real-time Updates)**: Implement WebSocket progress tracking
4. **Phase 4 (Optimization)**: Add caching, optimization, and monitoring

### Dependencies

- **BT-001b**: Requires completed data loading infrastructure
- **BT-002**: Requires performance metrics calculation functions
- **Celery**: Needs Redis for broker and result backend
- **WebSocket**: Requires Redis pub/sub for progress broadcasting

### Technical Decisions

1. **Why Celery over FastAPI BackgroundTasks?**
   - Better scalability (distributed workers)
   - Task persistence and retry
   - Progress tracking support
   - Separate resource allocation

2. **Why WebSocket over Server-Sent Events?**
   - Bi-directional communication (can cancel from client)
   - Better browser support
   - Lower latency

3. **Why Redis for rate limiting?**
   - Distributed rate limiting across instances
   - Fast atomic operations
   - Built-in expiration

### Monitoring and Observability

```python
# Add Prometheus metrics
from prometheus_client import Counter, Histogram, Gauge

backtest_requests = Counter("backtest_requests_total", "Total backtest requests", ["status"])
backtest_duration = Histogram("backtest_duration_seconds", "Backtest execution time")
active_backtests = Gauge("backtest_active", "Number of active backtests")

@router.post("/v1/backtest")
async def create_backtest(...):
    backtest_requests.labels(status="created").inc()
    active_backtests.inc()
    # ... rest of implementation
```

### Future Enhancements

- **Backtest scheduling**: Run backtests on cron schedule
- **Result comparison**: Compare multiple backtests side-by-side
- **Shared backtests**: Public backtest results with anonymized data
- **Backtest templates**: Save and reuse common configurations
- **Email notifications**: Alert when backtest completes
- **GraphQL API**: Alternative to REST for complex queries
