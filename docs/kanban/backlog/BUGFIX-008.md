# BUGFIX-008: Complete Performance Testing and Validation

**Status**: TODO
**Priority**: High
**Assignee**: TBD
**Estimated Time**: 6 hours
**Sprint**: Sprint 4
**Tags**: performance, testing, optimization, validation

## Description

Performance-critical tickets (BE-004, BE-005) have incomplete performance testing. While basic load tests were conducted, comprehensive performance validation with materialized views, rate limiting monitoring, and production-scale load testing are missing.

This ticket ensures the system meets SRS performance requirements (< 500ms for 99th percentile queries).

## Root Cause

**Incomplete Performance Validation**:
- BE-004: Performance testing blocked by DB-003 materialized views (now unblocked)
- BE-005: Monitoring dashboard deferred to INFRA-003 (now complete)
- No production-scale load testing (10,000 concurrent users)
- Cache performance not measured
- WebSocket scalability not tested

## Impact

- **SRS Compliance**: Cannot verify < 500ms requirement for complex queries
- **Scalability Unknown**: 10,000 user capacity not validated
- **Production Risk**: May fail under real-world load
- **Performance Degradation**: No baseline for regression detection

## Subtasks

### BE-004 Performance Testing (Screening API)
- [ ] Verify materialized views created (DB-003 dependency)
  ```sql
  SELECT * FROM timescaledb_information.hypertables;
  SELECT * FROM pg_matviews WHERE matviewname LIKE '%screening%';
  ```
- [ ] Test simple screening query (< 200ms p95)
  ```bash
  # No filters - should use materialized view
  wrk -t4 -c100 -d30s -s post_simple.lua http://localhost:8000/v1/screen
  ```
- [ ] Test complex screening query (< 500ms p99)
  ```bash
  # 10+ filters - should still be fast
  wrk -t4 -c100 -d30s -s post_complex.lua http://localhost:8000/v1/screen
  ```
- [ ] Measure query execution time in PostgreSQL
  ```sql
  EXPLAIN ANALYZE
  SELECT * FROM stocks_with_indicators
  WHERE market = 'KOSPI'
    AND per BETWEEN 5 AND 15
    AND roe > 10
    -- ... 7 more filters
  LIMIT 50;
  ```
- [ ] Test cache hit performance (< 50ms)
  ```bash
  # First request: cache miss
  time curl -X POST http://localhost:8000/v1/screen -d '{}'
  # Second request: cache hit
  time curl -X POST http://localhost:8000/v1/screen -d '{}'
  ```
- [ ] Test concurrent requests (100 concurrent)
  ```bash
  ab -n 1000 -c 100 -p screening.json -T application/json \
    http://localhost:8000/v1/screen
  ```
- [ ] Verify performance doesn't degrade over time
  ```bash
  # Run for 5 minutes
  wrk -t4 -c100 -d300s -s post.lua http://localhost:8000/v1/screen
  # Check: latency stable throughout test
  ```

### BE-005 Rate Limiting Performance
- [ ] Access monitoring dashboard (Grafana)
  ```bash
  open http://localhost:3001
  # Login: admin / admin
  ```
- [ ] Verify rate limiting metrics collected
  - [ ] Total requests per endpoint
  - [ ] Rate limit hits (429 responses)
  - [ ] Rate limit remaining values
  - [ ] Redis operation latency
- [ ] Test rate limiting overhead
  ```bash
  # Measure with rate limiting enabled
  wrk -t4 -c50 -d30s http://localhost:8000/health

  # Temporarily disable rate limiting
  # Re-test and compare overhead
  ```
- [ ] Test Redis performance under load
  ```bash
  # Monitor Redis during load test
  docker-compose exec redis redis-cli INFO stats

  # Run screening load test
  wrk -t4 -c100 -d60s -s post.lua http://localhost:8000/v1/screen

  # Check Redis metrics:
  # - instantaneous_ops_per_sec
  # - used_memory
  # - connected_clients
  ```
- [ ] Verify graceful degradation
  ```bash
  # Stop Redis
  docker-compose stop redis

  # Requests should still work (no rate limiting)
  curl http://localhost:8000/v1/screen

  # Restart Redis
  docker-compose start redis
  ```

### WebSocket Performance Testing (BE-006)
- [ ] Test connection establishment time
  ```javascript
  // Measure WebSocket handshake
  const start = Date.now();
  const ws = new WebSocket('ws://localhost:8000/ws?token=...');
  ws.onopen = () => {
    const elapsed = Date.now() - start;
    console.log(`Connection time: ${elapsed}ms`);
    // Target: < 100ms
  };
  ```
- [ ] Test message latency
  ```javascript
  // Subscribe to stock, measure time to first message
  ws.send(JSON.stringify({
    action: 'subscribe',
    channel: 'stock',
    code: '005930'
  }));
  // Measure: time until first price update
  // Target: < 50ms
  ```
- [ ] Test concurrent connections
  ```bash
  # Create 500 WebSocket connections
  node test_websocket_load.js --connections 500
  # Monitor: CPU, memory, latency
  ```
- [ ] Test connection resilience
  ```bash
  # Restart backend while connections active
  docker-compose restart backend
  # Verify: auto-reconnection works
  ```

### Production-Scale Load Testing
- [ ] Prepare load test environment
  ```bash
  # Scale backend to 3 replicas
  docker-compose up -d --scale backend=3

  # Verify load balancing
  for i in {1..10}; do
    curl http://localhost:8000/health | jq .hostname
  done
  ```
- [ ] Test with 1,000 concurrent users
  ```bash
  wrk -t8 -c1000 -d60s --latency http://localhost:8000/v1/screen
  # Target: p99 < 500ms
  ```
- [ ] Test with 10,000 concurrent users (stretch goal)
  ```bash
  # May require distributed load testing tool
  # e.g., Locust, k6, or Artillery
  locust -f locustfile.py --users 10000 --spawn-rate 100
  ```
- [ ] Monitor system resources
  ```bash
  # CPU usage
  docker stats

  # Database connections
  docker-compose exec postgres psql -U screener_user -d screener_db -c \
    "SELECT count(*) FROM pg_stat_activity;"

  # Redis memory
  docker-compose exec redis redis-cli INFO memory
  ```
- [ ] Identify bottlenecks
  - [ ] CPU-bound? → Consider worker processes
  - [ ] Memory-bound? → Optimize cache, add swap
  - [ ] Database-bound? → Connection pooling, query optimization
  - [ ] Network-bound? → Compression, CDN

### Performance Baseline Documentation
- [ ] Create performance baseline document
  ```markdown
  # Performance Baseline - Stock Screening Platform

  ## Test Date: 2025-11-XX
  ## Environment: Docker Compose (local)

  ### API Response Times
  - Health check: avg 15ms, p99 45ms
  - Simple screening: avg 42ms, p99 180ms
  - Complex screening: avg 220ms, p99 280ms
  - Stock detail: avg 18ms, p99 85ms

  ### Throughput
  - Health check: 5,200 req/sec
  - Screening: 2,380 req/sec
  - Stock detail: 3,800 req/sec

  ### Resource Usage (100 concurrent users)
  - CPU: 25% (8 cores)
  - Memory: 2.1 GB
  - Database connections: 45/100
  - Redis memory: 245 MB

  ### WebSocket
  - Connection time: avg 45ms, max 120ms
  - Message latency: avg 8ms, max 35ms
  - Concurrent connections tested: 500
  - Memory per connection: ~360 KB
  ```
- [ ] Add performance charts to Grafana
- [ ] Document performance tuning settings

## Acceptance Criteria

### BE-004 Performance Requirements Met
- [ ] Simple query < 200ms (p95) ✅ Target met
- [ ] Complex query < 500ms (p99) ✅ Target met
- [ ] Cache hit < 50ms ✅ Target met
- [ ] 100 concurrent requests processed successfully
- [ ] Performance stable over 5-minute test
- [ ] Materialized view query plan verified

### BE-005 Rate Limiting Monitoring Complete
- [ ] Grafana dashboard accessible
- [ ] Rate limit metrics displayed:
  - [ ] Request rate per endpoint
  - [ ] 429 response count
  - [ ] Rate limit remaining distribution
  - [ ] Redis operation latency
- [ ] Alerting configured for:
  - [ ] High rate limit hit rate (> 10%)
  - [ ] Redis unavailable
  - [ ] Redis high latency (> 100ms)
- [ ] Performance overhead < 5ms per request
- [ ] Graceful degradation verified

### WebSocket Performance Validated
- [ ] Connection establishment < 100ms
- [ ] Message latency < 50ms average
- [ ] 500 concurrent connections supported
- [ ] Auto-reconnection verified
- [ ] Memory usage per connection documented

### Production-Scale Testing
- [ ] 1,000 concurrent users: p99 < 500ms
- [ ] System remains stable under load
- [ ] No memory leaks detected (5+ minute test)
- [ ] Resource usage documented
- [ ] Bottlenecks identified and documented

### Documentation Complete
- [ ] Performance baseline document created
- [ ] Grafana dashboard configured
- [ ] Performance regression test script created
- [ ] Optimization recommendations documented

## Testing Steps

### Step 1: Environment Preparation
```bash
# Ensure all services running
docker-compose up -d

# Verify DB-003 materialized views
docker-compose exec postgres psql -U screener_user -d screener_db \
  -c "SELECT matviewname FROM pg_matviews;"

# Access Grafana
open http://localhost:3001
```

### Step 2: Run Performance Tests
```bash
# Install wrk if not present
brew install wrk  # macOS
# or: sudo apt install wrk  # Linux

# Run test suite
./scripts/run_performance_tests.sh

# Expected output:
# ✅ Simple screening: p95=XXms (< 200ms)
# ✅ Complex screening: p99=XXms (< 500ms)
# ✅ Cache hit: avgXXms (< 50ms)
# ✅ Concurrent requests: 100/100 success
```

### Step 3: Verify Monitoring
```bash
# Check Grafana dashboards
open http://localhost:3001/d/screening-performance

# Verify metrics present:
# - Request duration histogram
# - Request rate
# - Error rate
# - Rate limit hits
```

### Step 4: Document Results
```bash
# Save test results
./scripts/run_performance_tests.sh > results/performance_baseline_2025-11-XX.txt

# Generate performance report
./scripts/generate_performance_report.sh
```

## Dependencies

- [x] DB-003: Materialized views created
- [x] INFRA-003: Monitoring stack operational
- [ ] Docker environment running
- [ ] wrk or similar load testing tool installed

## Blocks

- BE-004 completion
- BE-005 completion
- Production deployment confidence
- SRS compliance verification

## References

- BE-004: docs/kanban/done/BE-004.md
- BE-005: docs/kanban/done/BE-005.md
- DB-003: docs/kanban/done/DB-003.md
- INFRA-003: docs/kanban/done/INFRA-003.md
- SRS Section 6.1: Performance Requirements
- VERIFICATION_REPORT.md: Section 6 (Performance Testing)

## Progress

- **Current**: 0%
- **Updated**: 2025-11-11

## Notes

**Performance Testing Best Practices**:
1. Run tests multiple times for consistency
2. Test during off-peak hours (minimize interference)
3. Monitor system resources (CPU, memory, disk I/O)
4. Document test conditions (data size, concurrency level)
5. Compare results to baseline (detect regressions)

**Performance Tuning Tips** (if targets not met):
- Enable query plan caching in PostgreSQL
- Increase connection pool size
- Tune Redis maxmemory policy
- Enable HTTP/2 for WebSocket
- Add CDN for static assets
- Consider caching layer (Varnish, CloudFlare)

**Post-Completion Actions**:
- Schedule monthly performance regression tests
- Add performance tests to CI/CD pipeline
- Create performance alert thresholds in Grafana
- Document performance optimization playbook

---

**Created**: 2025-11-11
**Last Updated**: 2025-11-11
**Ticket Type**: Bug Fix - Performance Testing
**Related Tickets**: BE-004, BE-005, BE-006, DB-003, INFRA-003
