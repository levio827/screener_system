# IND-001: Advanced Technical Indicators

## Metadata

| Field | Value |
|-------|-------|
| **ID** | IND-001 |
| **Title** | Add Advanced Technical Indicators |
| **Type** | Feature |
| **Status** | BACKLOG |
| **Priority** | P1 (High) |
| **Estimate** | 16 hours |
| **Sprint** | Sprint 5 |
| **Epic** | Extended Indicators |
| **Assignee** | TBD |
| **Created** | 2025-11-29 |
| **Tags** | `technical-analysis`, `indicators`, `airflow`, `data-pipeline` |
| **Blocks** | None |

## Description

Add advanced technical analysis indicators to expand the current indicator set from 30 to 60 indicators. This enhancement will provide traders and analysts with a comprehensive suite of technical indicators including Bollinger Bands, Ichimoku Cloud, trend/momentum indicators, volume indicators, and channel indicators.

The implementation will integrate with the existing Airflow data pipeline and calculated_indicators table, ensuring consistent data quality and real-time calculation capabilities.

## New Indicators

```python
# Bollinger Bands related
- bb_upper, bb_middle, bb_lower  # Bollinger Bands
- bb_percent_b                    # %B
- bb_bandwidth                    # Bandwidth

# Ichimoku Cloud
- ichimoku_tenkan                 # Conversion Line
- ichimoku_kijun                  # Base Line
- ichimoku_senkou_a               # Leading Span A
- ichimoku_senkou_b               # Leading Span B
- ichimoku_chikou                 # Lagging Span

# Trend/Momentum
- adx                             # Average Directional Index
- atr                             # Average True Range
- cci                             # Commodity Channel Index
- williams_r                      # Williams %R
- stochastic_rsi                  # Stochastic RSI
- ultimate_oscillator             # Ultimate Oscillator

# Volume
- obv                             # On Balance Volume
- vwap                            # Volume Weighted Average Price
- mfi                             # Money Flow Index
- chaikin_mf                      # Chaikin Money Flow
- accumulation_distribution       # A/D Line

# Others
- parabolic_sar                   # Parabolic SAR
- keltner_channel_upper           # Keltner Channel
- keltner_channel_lower
- donchian_channel_upper          # Donchian Channel
- donchian_channel_lower
```

## Subtasks

- [ ] **Backend Implementation**
  - [ ] Implement Bollinger Bands calculation (upper, middle, lower, %B, bandwidth)
  - [ ] Implement Ichimoku Cloud components (5 indicators)
  - [ ] Implement trend/momentum indicators (6 indicators)
  - [ ] Implement volume indicators (5 indicators)
  - [ ] Implement channel indicators (4 indicators)
  - [ ] Add unit tests for each indicator calculation
  - [ ] Validate indicator accuracy against reference data
- [ ] **Data Pipeline Integration**
  - [ ] Update Airflow DAG to include new indicators
  - [ ] Add new columns to calculated_indicators table
  - [ ] Implement backfill script for historical data
  - [ ] Add data quality checks for new indicators
- [ ] **API Integration**
  - [ ] Update API response schema to include new indicators
  - [ ] Add filtering support for new indicators
  - [ ] Update API documentation
  - [ ] Add pagination support for indicator data
- [ ] **Frontend Integration**
  - [ ] Add new indicators to screening filter UI
  - [ ] Implement indicator selection dropdown with categories
  - [ ] Add tooltip descriptions for each indicator
  - [ ] Update chart overlay options
- [ ] **Documentation & Testing**
  - [ ] Write indicator calculation formulas documentation
  - [ ] Create usage examples for each indicator
  - [ ] Perform integration testing with existing indicators
  - [ ] Conduct performance testing with full indicator set

## Implementation Details

### Backend Calculation Example (Python)

```python
import pandas as pd
import numpy as np
from typing import Dict, Any

class TechnicalIndicators:
    """Calculate advanced technical indicators"""

    @staticmethod
    def calculate_bollinger_bands(df: pd.DataFrame, period: int = 20, std_dev: float = 2.0) -> Dict[str, pd.Series]:
        """
        Calculate Bollinger Bands

        Args:
            df: DataFrame with 'close' column
            period: Moving average period (default: 20)
            std_dev: Standard deviation multiplier (default: 2.0)

        Returns:
            Dictionary with bb_upper, bb_middle, bb_lower, bb_percent_b, bb_bandwidth
        """
        bb_middle = df['close'].rolling(window=period).mean()
        std = df['close'].rolling(window=period).std()

        bb_upper = bb_middle + (std * std_dev)
        bb_lower = bb_middle - (std * std_dev)

        # %B indicator
        bb_percent_b = (df['close'] - bb_lower) / (bb_upper - bb_lower)

        # Bandwidth indicator
        bb_bandwidth = (bb_upper - bb_lower) / bb_middle

        return {
            'bb_upper': bb_upper,
            'bb_middle': bb_middle,
            'bb_lower': bb_lower,
            'bb_percent_b': bb_percent_b,
            'bb_bandwidth': bb_bandwidth
        }

    @staticmethod
    def calculate_ichimoku_cloud(df: pd.DataFrame) -> Dict[str, pd.Series]:
        """
        Calculate Ichimoku Cloud components

        Args:
            df: DataFrame with 'high', 'low', 'close' columns

        Returns:
            Dictionary with all Ichimoku components
        """
        # Tenkan-sen (Conversion Line): (9-period high + 9-period low)/2
        period9_high = df['high'].rolling(window=9).max()
        period9_low = df['low'].rolling(window=9).min()
        tenkan_sen = (period9_high + period9_low) / 2

        # Kijun-sen (Base Line): (26-period high + 26-period low)/2
        period26_high = df['high'].rolling(window=26).max()
        period26_low = df['low'].rolling(window=26).min()
        kijun_sen = (period26_high + period26_low) / 2

        # Senkou Span A (Leading Span A): (Tenkan-sen + Kijun-sen)/2
        senkou_span_a = ((tenkan_sen + kijun_sen) / 2).shift(26)

        # Senkou Span B (Leading Span B): (52-period high + 52-period low)/2
        period52_high = df['high'].rolling(window=52).max()
        period52_low = df['low'].rolling(window=52).min()
        senkou_span_b = ((period52_high + period52_low) / 2).shift(26)

        # Chikou Span (Lagging Span): Close shifted -26
        chikou_span = df['close'].shift(-26)

        return {
            'ichimoku_tenkan': tenkan_sen,
            'ichimoku_kijun': kijun_sen,
            'ichimoku_senkou_a': senkou_span_a,
            'ichimoku_senkou_b': senkou_span_b,
            'ichimoku_chikou': chikou_span
        }

    @staticmethod
    def calculate_adx(df: pd.DataFrame, period: int = 14) -> pd.Series:
        """
        Calculate Average Directional Index (ADX)

        Args:
            df: DataFrame with 'high', 'low', 'close' columns
            period: ADX period (default: 14)

        Returns:
            ADX values
        """
        high = df['high']
        low = df['low']
        close = df['close']

        # Calculate True Range
        tr1 = high - low
        tr2 = abs(high - close.shift(1))
        tr3 = abs(low - close.shift(1))
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

        # Calculate directional movement
        plus_dm = high.diff()
        minus_dm = -low.diff()

        plus_dm[plus_dm < 0] = 0
        minus_dm[minus_dm < 0] = 0

        # Smooth TR and DM
        tr_smooth = tr.rolling(window=period).sum()
        plus_dm_smooth = plus_dm.rolling(window=period).sum()
        minus_dm_smooth = minus_dm.rolling(window=period).sum()

        # Calculate DI
        plus_di = 100 * (plus_dm_smooth / tr_smooth)
        minus_di = 100 * (minus_dm_smooth / tr_smooth)

        # Calculate DX and ADX
        dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)
        adx = dx.rolling(window=period).mean()

        return adx

# Airflow DAG integration
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

def calculate_and_store_indicators(**context):
    """Calculate all technical indicators and store in database"""
    from sqlalchemy import create_engine
    import os

    engine = create_engine(os.getenv('DATABASE_URL'))

    # Fetch price data
    query = """
        SELECT stock_code, date, open, high, low, close, volume
        FROM stock_prices
        WHERE date >= NOW() - INTERVAL '1 year'
        ORDER BY stock_code, date
    """
    df = pd.read_sql(query, engine)

    results = []
    for stock_code, group in df.groupby('stock_code'):
        # Calculate all indicators
        bb_indicators = TechnicalIndicators.calculate_bollinger_bands(group)
        ichimoku_indicators = TechnicalIndicators.calculate_ichimoku_cloud(group)
        adx = TechnicalIndicators.calculate_adx(group)

        # Combine with stock info
        for idx, row in group.iterrows():
            indicator_data = {
                'stock_code': stock_code,
                'date': row['date'],
                **{k: v.iloc[idx] for k, v in bb_indicators.items()},
                **{k: v.iloc[idx] for k, v in ichimoku_indicators.items()},
                'adx': adx.iloc[idx]
            }
            results.append(indicator_data)

    # Bulk insert
    results_df = pd.DataFrame(results)
    results_df.to_sql('calculated_indicators', engine, if_exists='append', index=False)

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2025, 11, 29),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'calculate_advanced_technical_indicators',
    default_args=default_args,
    description='Calculate and store advanced technical indicators',
    schedule_interval='0 18 * * 1-5',  # 6PM on weekdays
    catchup=False,
)

calculate_task = PythonOperator(
    task_id='calculate_indicators',
    python_callable=calculate_and_store_indicators,
    dag=dag,
)
```

## Testing Strategy

### Unit Tests

```python
import pytest
import pandas as pd
import numpy as np
from indicators import TechnicalIndicators

class TestTechnicalIndicators:

    @pytest.fixture
    def sample_data(self):
        """Create sample price data for testing"""
        dates = pd.date_range('2025-01-01', periods=100)
        np.random.seed(42)

        data = pd.DataFrame({
            'date': dates,
            'open': 100 + np.random.randn(100).cumsum(),
            'high': 102 + np.random.randn(100).cumsum(),
            'low': 98 + np.random.randn(100).cumsum(),
            'close': 100 + np.random.randn(100).cumsum(),
            'volume': np.random.randint(1000000, 5000000, 100)
        })

        data['high'] = data[['open', 'high', 'close']].max(axis=1)
        data['low'] = data[['open', 'low', 'close']].min(axis=1)

        return data

    def test_bollinger_bands_calculation(self, sample_data):
        """Test Bollinger Bands calculation"""
        result = TechnicalIndicators.calculate_bollinger_bands(sample_data, period=20, std_dev=2.0)

        # Check all components are present
        assert 'bb_upper' in result
        assert 'bb_middle' in result
        assert 'bb_lower' in result
        assert 'bb_percent_b' in result
        assert 'bb_bandwidth' in result

        # Check relationships
        assert (result['bb_upper'] >= result['bb_middle']).all()
        assert (result['bb_middle'] >= result['bb_lower']).all()

        # Check %B is between 0 and 1 when price is within bands
        valid_percent_b = result['bb_percent_b'].dropna()
        assert valid_percent_b.min() >= -0.5  # Allow some overshooting
        assert valid_percent_b.max() <= 1.5

    def test_ichimoku_cloud_calculation(self, sample_data):
        """Test Ichimoku Cloud calculation"""
        result = TechnicalIndicators.calculate_ichimoku_cloud(sample_data)

        # Check all components are present
        expected_keys = ['ichimoku_tenkan', 'ichimoku_kijun', 'ichimoku_senkou_a',
                        'ichimoku_senkou_b', 'ichimoku_chikou']
        for key in expected_keys:
            assert key in result
            assert len(result[key]) == len(sample_data)

    def test_adx_calculation(self, sample_data):
        """Test ADX calculation"""
        result = TechnicalIndicators.calculate_adx(sample_data, period=14)

        # ADX should be between 0 and 100
        valid_adx = result.dropna()
        assert valid_adx.min() >= 0
        assert valid_adx.max() <= 100

        # Check expected number of NaN values
        assert result.isna().sum() >= 13  # At least period-1 NaN values

    def test_indicator_null_handling(self, sample_data):
        """Test that indicators handle null values correctly"""
        # Introduce some null values
        sample_data.loc[10:15, 'close'] = np.nan

        result = TechnicalIndicators.calculate_bollinger_bands(sample_data)

        # Should not raise exception
        assert result is not None
        assert 'bb_middle' in result

### Integration Tests

```python
def test_airflow_dag_integration():
    """Test Airflow DAG can calculate and store indicators"""
    from airflow.models import DagBag

    dagbag = DagBag(dag_folder='dags/')
    dag = dagbag.get_dag('calculate_advanced_technical_indicators')

    assert dag is not None
    assert len(dag.tasks) > 0
    assert 'calculate_indicators' in [task.task_id for task in dag.tasks]

def test_database_schema_compatibility():
    """Test that calculated indicators fit database schema"""
    from sqlalchemy import create_engine, inspect
    import os

    engine = create_engine(os.getenv('TEST_DATABASE_URL'))
    inspector = inspect(engine)

    columns = [col['name'] for col in inspector.get_columns('calculated_indicators')]

    expected_columns = ['bb_upper', 'bb_middle', 'bb_lower', 'bb_percent_b', 'bb_bandwidth',
                       'ichimoku_tenkan', 'ichimoku_kijun', 'adx']

    for col in expected_columns:
        assert col in columns, f"Column {col} missing from calculated_indicators table"
```

### End-to-End Tests

```python
def test_e2e_indicator_calculation_pipeline():
    """Test complete pipeline from data fetch to API response"""
    import requests

    # Trigger DAG run
    response = requests.post(
        'http://airflow:8080/api/v1/dags/calculate_advanced_technical_indicators/dagRuns',
        json={"conf": {}},
        auth=('admin', 'admin')
    )
    assert response.status_code == 200

    # Wait for completion
    import time
    time.sleep(60)

    # Verify API returns new indicators
    response = requests.get('http://api:8000/api/stocks/005930/indicators')
    data = response.json()

    assert 'bb_upper' in data
    assert 'ichimoku_tenkan' in data
    assert 'adx' in data
```

## Acceptance Criteria

- [ ] 30 new technical indicator calculation logic implemented and tested
- [ ] Airflow DAG updated to calculate new indicators daily
- [ ] All new indicators added to screening filters with proper categorization
- [ ] API response includes new indicators with proper documentation
- [ ] Frontend filter UI updated with new indicators and tooltips
- [ ] Indicator description tooltips provide clear explanations
- [ ] Performance benchmark: Calculation time < 5 seconds per stock
- [ ] Data accuracy validated against reference implementations (TA-Lib)

## Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Calculation accuracy discrepancies | Medium | High | Validate against TA-Lib and TradingView, implement comprehensive unit tests |
| Performance degradation with 60 indicators | High | Medium | Implement parallel processing, optimize SQL queries, add database indexes |
| Airflow DAG timeout with large dataset | Medium | High | Implement chunked processing, add timeout monitoring, optimize batch size |
| Database schema migration issues | Low | High | Test migration on staging, implement rollback plan, use Alembic migrations |
| Frontend UI becomes cluttered | Medium | Medium | Implement categorized dropdown, add search functionality, create presets |
| Missing historical data for new indicators | Low | Medium | Implement backfill script with progress tracking, validate data completeness |

## Performance Requirements

- **Calculation Speed**: < 5 seconds per stock for all 60 indicators
- **API Response Time**: < 200ms for indicator data endpoint
- **Database Query Time**: < 100ms for filtered indicator queries
- **Memory Usage**: < 2GB during batch calculation
- **Airflow DAG Execution**: Complete within 1 hour for all stocks
- **Frontend Rendering**: < 50ms to render indicator filter UI

## Security Considerations

- **Data Validation**: Validate all indicator inputs to prevent NaN/Inf propagation
- **SQL Injection Prevention**: Use parameterized queries for all database operations
- **Rate Limiting**: Apply rate limits to indicator calculation API endpoints
- **Access Control**: Restrict indicator calculation triggers to authenticated users
- **Data Integrity**: Implement checksums for indicator data to detect corruption
- **Audit Logging**: Log all indicator calculation runs with timestamps and results

## Error Handling

```python
class IndicatorCalculationError(Exception):
    """Base exception for indicator calculation errors"""
    pass

class InsufficientDataError(IndicatorCalculationError):
    """Raised when not enough data points for calculation"""
    pass

def safe_calculate_indicators(df: pd.DataFrame, stock_code: str) -> Dict[str, Any]:
    """
    Safely calculate indicators with comprehensive error handling

    Args:
        df: Price data DataFrame
        stock_code: Stock code for logging

    Returns:
        Dictionary of calculated indicators

    Raises:
        InsufficientDataError: If not enough data points
    """
    import logging

    logger = logging.getLogger(__name__)

    try:
        # Validate minimum data requirements
        min_required_rows = 52  # For Ichimoku Cloud
        if len(df) < min_required_rows:
            raise InsufficientDataError(
                f"Stock {stock_code} has only {len(df)} rows, need {min_required_rows}"
            )

        # Validate data quality
        required_columns = ['open', 'high', 'low', 'close', 'volume']
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise IndicatorCalculationError(
                f"Missing required columns: {missing_columns}"
            )

        # Check for null values
        null_counts = df[required_columns].isnull().sum()
        if null_counts.any():
            logger.warning(f"Stock {stock_code} has null values: {null_counts.to_dict()}")
            # Forward fill null values
            df = df.fillna(method='ffill')

        # Calculate indicators with individual error handling
        results = {}

        try:
            results.update(TechnicalIndicators.calculate_bollinger_bands(df))
        except Exception as e:
            logger.error(f"Bollinger Bands calculation failed for {stock_code}: {e}")
            results.update({
                'bb_upper': None, 'bb_middle': None, 'bb_lower': None,
                'bb_percent_b': None, 'bb_bandwidth': None
            })

        try:
            results.update(TechnicalIndicators.calculate_ichimoku_cloud(df))
        except Exception as e:
            logger.error(f"Ichimoku calculation failed for {stock_code}: {e}")
            results.update({
                'ichimoku_tenkan': None, 'ichimoku_kijun': None,
                'ichimoku_senkou_a': None, 'ichimoku_senkou_b': None,
                'ichimoku_chikou': None
            })

        try:
            results['adx'] = TechnicalIndicators.calculate_adx(df)
        except Exception as e:
            logger.error(f"ADX calculation failed for {stock_code}: {e}")
            results['adx'] = None

        return results

    except InsufficientDataError:
        logger.warning(f"Insufficient data for {stock_code}, skipping")
        raise
    except Exception as e:
        logger.error(f"Unexpected error calculating indicators for {stock_code}: {e}")
        raise IndicatorCalculationError(f"Calculation failed: {e}") from e
```

## Dependencies

- **Technical**: pandas >= 1.3.0, numpy >= 1.21.0, TA-Lib >= 0.4.24
- **Infrastructure**: Airflow >= 2.5.0, PostgreSQL >= 13
- **External**: Data pipeline (Airflow), calculated_indicators table schema
- **Blocked By**: None
- **Blocks**: Frontend indicator visualization features

## Notes

- Consider using TA-Lib library for validated indicator calculations
- Implement caching for frequently requested indicator combinations
- Add indicator presets (e.g., "Momentum Pack", "Volatility Pack") for ease of use
- Consider batch calculation optimization using vectorized operations
- Document indicator formulas in user-facing documentation
- Plan for future ML-based indicator feature engineering
- Monitor calculation accuracy against established benchmarks
- Consider implementing custom indicators based on user feedback

## Progress

**Status**: 0% - Not started

**Next Steps**:
1. Set up development environment with TA-Lib and required dependencies
2. Implement and unit test Bollinger Bands calculations
3. Implement and unit test Ichimoku Cloud calculations
4. Continue with remaining indicator categories

## References

- [IMPROVEMENT_TICKETS.md](../../IMPROVEMENT_TICKETS.md) - Epic 5: Extended Indicators
- [TA-Lib Documentation](https://ta-lib.org/)
- [Investopedia Technical Indicators](https://www.investopedia.com/terms/t/technicalindicator.asp)
- [TradingView Indicator Reference](https://www.tradingview.com/support/solutions/43000502233-indicators/)
