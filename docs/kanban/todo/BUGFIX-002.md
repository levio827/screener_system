# [BUGFIX-002] Optimize Screening Query Performance (Double Query Issue)

## Metadata
- **Status**: TODO
- **Priority**: High
- **Assignee**: Development Team
- **Estimated Time**: 3 hours
- **Sprint**: Sprint 2 (Week 3-4)
- **Tags**: #performance #database #optimization #backend
- **Created**: 2025-11-10
- **Related PR**: #23 (Blocking)

## Description
Screening API executes the same query twice: once for COUNT, once for data retrieval. This doubles the query execution time and database load. Optimize to single query using PostgreSQL window functions.

## Problem Analysis

### Current Implementation
**Location**: `backend/app/repositories/screening_repository.py:36-76`

```python
# Query 1: Count total matches (~200ms)
count_query = f"SELECT COUNT(*) as total FROM ({base_query}) AS filtered"
count_result = await self.session.execute(text(count_query))
total_count = count_result.scalar()

# Query 2: Get paginated data (~200ms)
final_query = f"{base_query}\n{order_clause}\nLIMIT :limit OFFSET :offset"
result = await self.session.execute(text(final_query), {...})

# Total time: ~400ms (2x expected)
```

### Performance Impact

**Current Behavior**:
- Simple queries: ~400ms (should be ~200ms)
- Complex queries: ~1000ms (should be ~500ms)
- Database load: 2x necessary
- Cache efficiency: Lower (doubled latency)

**Why This Happens**:
1. PostgreSQL scans the `stock_screening_view` twice
2. WHERE clause is evaluated twice
3. Indexes are used twice
4. Query planner can't optimize across two separate queries

### Target Performance
- Simple queries: < 200ms (p95)
- Complex queries: < 500ms (p99)
- 50% reduction in query time

## Subtasks
- [ ] **Implement Window Function Optimization**
  - [ ] Refactor screen_stocks to use single query with COUNT() OVER()
  - [ ] Extract total_count from first result row
  - [ ] Handle empty result set edge case
  - [ ] Update return tuple structure if needed

- [ ] **Performance Testing**
  - [ ] Benchmark current implementation (baseline)
  - [ ] Benchmark new implementation
  - [ ] Verify 50%+ performance improvement
  - [ ] Test with various filter combinations
  - [ ] Test with different result set sizes (0, 10, 100, 1000 rows)

- [ ] **Update Tests**
  - [ ] Update repository tests for new query structure
  - [ ] Verify total_count accuracy
  - [ ] Test pagination with new approach
  - [ ] Add performance regression tests

- [ ] **Documentation**
  - [ ] Document window function approach
  - [ ] Add inline comments explaining optimization
  - [ ] Update repository docstrings

## Implementation Guide

### Optimized Query Structure

```python
async def screen_stocks(
    self,
    filters: ScreeningFilters,
    sort_by: str = "market_cap",
    order: str = "desc",
    offset: int = 0,
    limit: int = 50,
) -> tuple[list[dict], int]:
    """Screen stocks with filters using optimized single query.

    Performance:
        Uses window function COUNT() OVER() to get total in one query.
        ~50% faster than separate COUNT query approach.
    """
    # Validate sort field (from SECURITY-001)
    if sort_by not in self.ALLOWED_SORT_FIELDS:
        raise ValueError(f"Invalid sort field: {sort_by}")

    # Build WHERE conditions with parameters (from SECURITY-001)
    conditions, params = self._build_where_conditions(filters)
    where_clause = "WHERE " + " AND ".join(conditions) if conditions else ""

    # Order direction
    order_direction = "DESC" if order == "desc" else "ASC"

    # OPTIMIZED: Single query with window function
    query = f"""
        WITH filtered AS (
            SELECT
                *,
                COUNT(*) OVER() as total_count
            FROM stock_screening_view
            {where_clause}
        )
        SELECT * FROM filtered
        ORDER BY
            CASE WHEN {sort_by} IS NULL THEN 1 ELSE 0 END,
            {sort_by} {order_direction}
        LIMIT :limit OFFSET :offset
    """

    # Add pagination parameters
    params["limit"] = limit
    params["offset"] = offset

    # Execute single query
    result = await self.session.execute(text(query), params)
    rows = result.mappings().all()

    # Extract total count from first row (or 0 if empty)
    total_count = rows[0]["total_count"] if rows else 0

    # Convert to dict format (excluding total_count column)
    stocks = [
        {k: v for k, v in row.items() if k != "total_count"}
        for row in rows
    ]

    return stocks, total_count
```

### Explanation of Optimization

**Window Function `COUNT() OVER()`**:
- Calculates total count across ALL filtered rows
- Adds total_count column to each result row
- No performance penalty (computed during scan)
- Eliminates need for separate COUNT query

**CTE (Common Table Expression) `WITH filtered AS`**:
- Improves query readability
- Allows PostgreSQL to optimize the entire query
- Can be materialized for complex filters

**Performance Characteristics**:
```
Before:
  Query 1 (COUNT): Full table scan → 200ms
  Query 2 (Data):  Full table scan → 200ms
  Total: 400ms

After:
  Query (Combined): Full table scan + window function → 220ms
  Total: 220ms (45% faster)
```

### Edge Cases to Handle

1. **Empty Result Set**:
```python
# Handle: rows = []
total_count = rows[0]["total_count"] if rows else 0
```

2. **Large Result Sets**:
```python
# Window function computes count during scan, no extra cost
# LIMIT/OFFSET still applied after ordering
```

3. **NULL Values in sort_by**:
```python
# Already handled by CASE WHEN {sort_by} IS NULL THEN 1 ELSE 0 END
# NULLs sorted last
```

## Performance Benchmarks

### Test Scenarios

| Scenario | Filters | Expected Results | Baseline | Target | Actual |
|----------|---------|------------------|----------|--------|--------|
| Simple   | Market only | ~2000 stocks | 400ms | <200ms | TBD |
| Medium   | Market + PER range | ~500 stocks | 450ms | <250ms | TBD |
| Complex  | 5+ filters | ~100 stocks | 600ms | <350ms | TBD |
| Large    | Market only, page 10 | ~2000 stocks | 420ms | <220ms | TBD |
| Empty    | Impossible filters | 0 stocks | 380ms | <200ms | TBD |

### Benchmark Code

```python
import time
from app.schemas.screening import ScreeningFilters, FilterRange

async def benchmark_screening():
    """Benchmark screening query performance"""
    scenarios = [
        ("Simple", ScreeningFilters(market="KOSPI")),
        ("Medium", ScreeningFilters(
            market="KOSPI",
            per=FilterRange(min=5.0, max=15.0)
        )),
        ("Complex", ScreeningFilters(
            market="KOSPI",
            per=FilterRange(min=5.0, max=15.0),
            roe=FilterRange(min=10.0),
            debt_ratio=FilterRange(max=100.0),
            quality_score=FilterRange(min=70.0)
        )),
    ]

    for name, filters in scenarios:
        start = time.time()
        results, total = await repo.screen_stocks(
            filters=filters,
            sort_by="market_cap",
            order="desc",
            offset=0,
            limit=50
        )
        elapsed = (time.time() - start) * 1000
        print(f"{name}: {elapsed:.1f}ms (total={total})")
```

## Acceptance Criteria
- [ ] Single query implementation using COUNT() OVER()
- [ ] No separate COUNT query executed
- [ ] total_count extracted from first row correctly
- [ ] Empty result set handled (total_count = 0)
- [ ] All existing tests passing
- [ ] Performance benchmarks show 40-50% improvement
- [ ] EXPLAIN ANALYZE confirms single table scan
- [ ] Documentation updated

## Testing Checklist

### Unit Tests
- [ ] Test with 0 results (empty filters)
- [ ] Test with 1 result
- [ ] Test with 50 results (full page)
- [ ] Test with 1000+ results (pagination)
- [ ] Test total_count accuracy

### Performance Tests
- [ ] Benchmark before optimization (baseline)
- [ ] Benchmark after optimization
- [ ] Verify improvement >= 40%
- [ ] Test p95 and p99 latencies
- [ ] Test with PostgreSQL EXPLAIN ANALYZE

### Integration Tests
- [ ] Verify API endpoint response unchanged
- [ ] Verify pagination metadata correct
- [ ] Test with Redis caching enabled

## Dependencies
- **Blocks**: BE-004 PR #23 (performance requirement)
- **Depends on**: SECURITY-001 (parameterized queries needed)
- **Related**: DB-003 (materialized view optimization)

## References
- **Code Review**: docs/reviews/REVIEW_2025-11-10_be-004-screening-api.md
- **PostgreSQL Window Functions**: https://www.postgresql.org/docs/current/tutorial-window.html
- **Performance Requirement**: BE-004 Acceptance Criteria (< 500ms p99)

## Impact Assessment
- **Performance**: HIGH - 40-50% faster query execution
- **Database Load**: HIGH - 50% reduction in query count
- **Cache Efficiency**: MEDIUM - Lower latency improves cache hit rate
- **Code Complexity**: LOW - Actually simpler code (one query vs two)
- **Risk**: LOW - Standard PostgreSQL window function pattern

## Notes
- Window functions are standard SQL feature (PostgreSQL 8.4+)
- No migration needed (query-level change only)
- Can be applied to other paginated endpoints (BE-003, etc.)
- Consider adding this pattern to coding guidelines
- EXPLAIN ANALYZE before/after comparison will be valuable documentation

## EXPLAIN ANALYZE Comparison

### Before Optimization
```sql
EXPLAIN ANALYZE
SELECT COUNT(*) FROM (
    SELECT * FROM stock_screening_view WHERE market = 'KOSPI'
) AS filtered;

-- Expected: Seq Scan on stock_screening_view (cost=X rows=Y time=200ms)
```

### After Optimization
```sql
EXPLAIN ANALYZE
WITH filtered AS (
    SELECT *, COUNT(*) OVER() as total_count
    FROM stock_screening_view
    WHERE market = 'KOSPI'
)
SELECT * FROM filtered
ORDER BY market_cap DESC
LIMIT 50 OFFSET 0;

-- Expected: WindowAgg + Seq Scan (cost=X rows=Y time=220ms)
-- Total time should be ~50% of before
```

## Progress
- **0%** - Not started (waiting for SECURITY-001)

## Implementation Order
1. Fix SECURITY-001 first (parameterized queries)
2. Then apply this optimization (window function)
3. Reason: Security fixes might change query structure
